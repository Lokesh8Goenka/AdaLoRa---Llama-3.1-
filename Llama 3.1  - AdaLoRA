{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9401942,"sourceType":"datasetVersion","datasetId":5707438},{"sourceId":104449,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ******************************* 0 ******************************* \n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-20T03:50:48.352541Z","iopub.execute_input":"2024-09-20T03:50:48.352849Z","iopub.status.idle":"2024-09-20T03:50:48.712390Z","shell.execute_reply.started":"2024-09-20T03:50:48.352815Z","shell.execute_reply":"2024-09-20T03:50:48.711497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n/kaggle/input/combined-data/combines_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Necessary until transformers package is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel = \"/kaggle/input/llama-3.1/transformers/8b/1\"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = transformers.pipeline(\n    \"text-generation\", model=model,max_length = 2048, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline('''Generate 15 MCQs from the following passage of different difficulty levels. \nThe questions should be of easy, medium and hard difficulty level, where each difficulty level should have 5 questions each.\nHorticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.\n''',max_length = 2048)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Llama 3.1 8B-Instruct","metadata":{}},{"cell_type":"code","source":"passage = '''Horticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.'''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. '''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are an assitant social studies teacher in a High School.\"},\n    {\"role\": \"user\", \"content\": prompt + passage},\n]\n\noutputs = pipeline(\n    messages,\n    max_new_tokens=2048,\n)\nprint(outputs[0][\"generated_text\"][-1])\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generated MCQS on ","metadata":{}},{"cell_type":"markdown","source":"\"**Section 1: Recall (Easy Difficulty Level)**\\n\\n1. What is Horticulture?\\n   a) Growing vegetables, flowers and fruits for commercial use\\n   b) Farming for subsistence\\n   c) Farming for commercial use\\n   d) Growing crops for household use\\n\\nAnswer: a) Growing vegetables, flowers and fruits for commercial use\\n\\n2. What are the important inputs in a farm system?\\n   a) Seeds, fertilisers, machinery and labour\\n   b) Seeds, fertilisers, animals and soil\\n   c) Seeds, labour, machinery and water\\n   d) Seeds, fertilisers, animals and tools\\n\\nAnswer: a) Seeds, fertilisers, machinery and labour\\n\\n3. What are the outputs from a farm system?\\n   a) Crops, wool, dairy and poultry products\\n   b) Crops, seeds, fertilisers and labour\\n   c) Crops, animals, tools and water\\n   d) Crops, animals, seeds and soil\\n\\nAnswer: a) Crops, wool, dairy and poultry products\\n\\n4. What is subsistence farming?\\n   a) Farming to meet the needs of the farmer's family\\n   b) Farming for commercial use\\n   c) Farming for household use\\n   d) Farming for export\\n\\nAnswer: a) Farming to meet the needs of the farmer's family\\n\\n5. What is intensive subsistence agriculture?\\n   a) Farming using simple tools and more labour\\n   b) Farming using complex tools and less labour\\n   c) Farming using animals and household labour\\n   d) Farming using machines and commercial labour\\n\\nAnswer: a) Farming using simple tools and more labour\\n\\n\n**Section 2: Analyze (Medium Difficulty Level)**\\n\\n6. What are the geographical conditions that permit intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Large number of days with sunshine and fertile soils\\n   b) Heavy rainfall and quick regeneration of vegetation\\n   c) Semi-arid and arid regions\\n   d) Thickly populated areas\\n\\nAnswer: a) Large number of days with sunshine and fertile soils\\n\\n7. What are the main crops grown in intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Rice, wheat, maize, pulses and oilseeds\\n   b) Maize, yam, potatoes and cassava\\n   c) Sheep, camel, yak and goats\\n   d) Cattle, buffalo and horses\\n\\nAnswer: a) Rice, wheat, maize, pulses and oilseeds\\n\\n8. What is shifting cultivation? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Shifting from one plot of land to another\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Shifting from one plot of land to another\\n\\n9. What is nomadic herding? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Moving from place to place with animals for fodder and water\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n10. What are the products provided by sheep, camel, yak and goats in nomadic herding? (Bloom's Taxonomy: Analyze)\\n    a) Milk, meat, wool, hides and other products\\n    b) Crops, seeds, fertilisers and labour\\n    c) Crops, animals, tools and water\\n    d) Crops, animals, seeds and soil\\n\\nAnswer: a) Milk, meat, wool, hides and other products\\n\\n\n**Section 3: Evaluate (Hard Difficulty Level)**\\n\\n11. What are the limitations of subsistence farming? (Bloom's Taxonomy: Evaluate)\\n    a) Low levels of technology and household labour\\n    b) High levels of technology and commercial labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Low levels of technology and household labour\\n\\n12. What are the advantages of intensive subsistence agriculture? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: c) Large number of days with sunshine and fertile soils\\n\\n13. What are the limitations of shifting cultivation? (Bloom's Taxonomy: Evaluate)\\n    a) Soil loses its fertility and is abandoned\\n    b) Soil retains its fertility and is reused\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Soil loses its fertility and is abandoned\\n\\n14. What are the advantages of nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Moving from place to place with animals for fodder and water\\n    d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n15. What are the geographical conditions that permit nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) Large number of days with sunshine and fertile soils\\n    b) Heavy rainfall and quick regeneration of vegetation\\n    c) Semi-arid and arid regions\\n    d) Thickly populated areas\\n\\nAnswer: c) Semi-arid and arid regions\"}","metadata":{}},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{}},{"cell_type":"markdown","source":"## Using ADALORA\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 0.1 ******************************* \n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:50:48.714081Z","iopub.execute_input":"2024-09-20T03:50:48.714860Z","iopub.status.idle":"2024-09-20T03:51:09.707875Z","shell.execute_reply.started":"2024-09-20T03:50:48.714814Z","shell.execute_reply":"2024-09-20T03:51:09.706946Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.2 ******************************* \nimport bitsandbytes as bnb\nprint(bnb.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:09.710113Z","iopub.execute_input":"2024-09-20T03:51:09.710968Z","iopub.status.idle":"2024-09-20T03:51:15.520084Z","shell.execute_reply.started":"2024-09-20T03:51:09.710919Z","shell.execute_reply":"2024-09-20T03:51:15.519081Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.3 ******************************* \n!pip install transformers\n!pip install peft  # This is for Parameter-Efficient Fine-Tuning (PEFT)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:15.521147Z","iopub.execute_input":"2024-09-20T03:51:15.521563Z","iopub.status.idle":"2024-09-20T03:51:41.845112Z","shell.execute_reply.started":"2024-09-20T03:51:15.521528Z","shell.execute_reply":"2024-09-20T03:51:41.843952Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:52:00.948770Z","iopub.execute_input":"2024-09-20T03:52:00.949420Z","iopub.status.idle":"2024-09-20T03:52:00.953663Z","shell.execute_reply.started":"2024-09-20T03:52:00.949380Z","shell.execute_reply":"2024-09-20T03:52:00.952514Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T15:59:53.311822Z","iopub.execute_input":"2024-09-19T15:59:53.312134Z","iopub.status.idle":"2024-09-19T16:02:06.316808Z","shell.execute_reply.started":"2024-09-19T15:59:53.312079Z","shell.execute_reply":"2024-09-19T16:02:06.314126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting transformers\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m743.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\nSuccessfully installed transformers-4.44.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"019e3f94933541d58757d37867fbe569"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39menable_mem_efficient_sdp(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39menable_flash_sdp(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch_dtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:895\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 895\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    906\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:286\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3960\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3951\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3953\u001b[0m     (\n\u001b[1;32m   3954\u001b[0m         model,\n\u001b[1;32m   3955\u001b[0m         missing_keys,\n\u001b[1;32m   3956\u001b[0m         unexpected_keys,\n\u001b[1;32m   3957\u001b[0m         mismatched_keys,\n\u001b[1;32m   3958\u001b[0m         offload_index,\n\u001b[1;32m   3959\u001b[0m         error_msgs,\n\u001b[0;32m-> 3960\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3980\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4434\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4430\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4431\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4432\u001b[0m                 )\n\u001b[1;32m   4433\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4434\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4435\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4436\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4437\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4438\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4439\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4441\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4442\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4449\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4451\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4453\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:961\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    950\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_quantized\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    959\u001b[0m ):\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/modeling.py:416\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    414\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 416\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model = pipeline.model","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:02:06.317905Z","iopub.status.idle":"2024-09-19T16:02:06.318301Z","shell.execute_reply.started":"2024-09-19T16:02:06.318095Z","shell.execute_reply":"2024-09-19T16:02:06.318128Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adalora\n\nfrom peft import AdaLoraConfig, AdaLoraModel\n\nadalora_config = AdaLoraConfig(\n    task_type=\"CAUSAL_LM\",\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\n\nmodel = AdaLoraModel(model, adalora_config, \"default\")\n\n# number of trainable parameters\nnum_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n#total number of parameters\ntotal_params = sum(p.numel() for p in model.parameters())\n\n# percentage of trainable parameters\npercentage_trainable_params = (num_trainable_params / total_params) * 100\n\nprint(\"Number of trainable parameters:\", num_trainable_params)\nprint(\"Total number of parameters:\", total_params)\nprint(\"Percentage of trainable parameters:\", percentage_trainable_params)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:02:06.320195Z","iopub.status.idle":"2024-09-19T16:02:06.320571Z","shell.execute_reply.started":"2024-09-19T16:02:06.320377Z","shell.execute_reply":"2024-09-19T16:02:06.320396Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading dataset","metadata":{}},{"cell_type":"code","source":"# ******************************* 1 ******************************* \nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/combined-data/combines_dataset.csv', encoding='ISO-8859-1')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:41.848289Z","iopub.execute_input":"2024-09-20T03:51:41.849113Z","iopub.status.idle":"2024-09-20T03:51:41.934522Z","shell.execute_reply.started":"2024-09-20T03:51:41.849073Z","shell.execute_reply":"2024-09-20T03:51:41.933842Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.1 ******************************* \n# Display the first few rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:41.935511Z","iopub.execute_input":"2024-09-20T03:51:41.935794Z","iopub.status.idle":"2024-09-20T03:51:41.958969Z","shell.execute_reply.started":"2024-09-20T03:51:41.935762Z","shell.execute_reply":"2024-09-20T03:51:41.957997Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                             passage  \\\n0  This transformation from a plant to a finished...   \n1  People are a nationâs greatest resource. Nat...   \n2  Have you ever given a thought to the fact that...   \n3  In a small village in Tanzania, Africa, Mamba ...   \n4  Water, electricity, rickshaw, vegetable and te...   \n\n                                                mcqs  \n0  ['## Agriculture and Economic Activities: An M...  \n1  ['## Population Studies Test\\n', '\\n', '**Inst...  \n2  ['## The Journey of Your Notebook: A Social St...  \n3  ['## Social Studies Test: Land as a Resource\\n...  \n4  ['## Agriculture and Farming: An MCQ Test\\n', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passage</th>\n      <th>mcqs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This transformation from a plant to a finished...</td>\n      <td>['## Agriculture and Economic Activities: An M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>People are a nationâs greatest resource. Nat...</td>\n      <td>['## Population Studies Test\\n', '\\n', '**Inst...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Have you ever given a thought to the fact that...</td>\n      <td>['## The Journey of Your Notebook: A Social St...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In a small village in Tanzania, Africa, Mamba ...</td>\n      <td>['## Social Studies Test: Land as a Resource\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Water, electricity, rickshaw, vegetable and te...</td>\n      <td>['## Agriculture and Farming: An MCQ Test\\n', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \n# Import the splitting function\nfrom sklearn.model_selection import train_test_split\n\n# Split the formatted data into training and testing sets\ntrain_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n\n# Check the lengths of the train and test splits\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Testing set size: {len(test_data)}\")\n\n# Optional: Print the first entry from the training and test set\nprint(f\"First training example: {train_data.iloc[0]}\")\nprint(len(train_data),\"\\n\")\nprint(f\"First testing example: {test_data.iloc[0]}\")\nprint(len(test_data))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:41.960161Z","iopub.execute_input":"2024-09-20T03:51:41.960623Z","iopub.status.idle":"2024-09-20T03:51:42.629582Z","shell.execute_reply.started":"2024-09-20T03:51:41.960570Z","shell.execute_reply":"2024-09-20T03:51:42.628335Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Training set size: 100\nTesting set size: 43\nFirst training example: passage    European Imperialism The American empires of S...\nmcqs       ['## European Imperialism - MCQ Test\\n', '\\n',...\nName: 84, dtype: object\n100 \n\nFirst testing example: passage    1. A Mosaic of Religious Beliefs and Practices...\nmcqs       ['## MCQ Test: A Mosaic of Religious Beliefs\\n...\nName: 117, dtype: object\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:42.631237Z","iopub.execute_input":"2024-09-20T03:51:42.632108Z","iopub.status.idle":"2024-09-20T03:51:42.637695Z","shell.execute_reply.started":"2024-09-20T03:51:42.632070Z","shell.execute_reply":"2024-09-20T03:51:42.636571Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"passages = train_data['passage'].tolist()\nmcqs = train_data['mcqs'].tolist()\n\npassage_test = test_data['passage'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:42.639247Z","iopub.execute_input":"2024-09-20T03:51:42.639895Z","iopub.status.idle":"2024-09-20T03:51:43.367892Z","shell.execute_reply.started":"2024-09-20T03:51:42.639851Z","shell.execute_reply":"2024-09-20T03:51:43.366760Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.2 ******************************* \ntrain_data = []\n\nfor passage, mcq in zip(passages, mcqs):\n    formatted_entry = (\n        \"<begin_of_text> \"\n        \"<start_header_id>passage<end_header_id> \" + passage.strip() + \" \"\n        \"<eom_id> \"\n        \"<start_header_id>questions<end_header_id> \" + mcq.strip() + \" \"\n        \"<eot_id> \"\n        \"<end_of_text>\"\n    )\n    train_data.append(formatted_entry)\n\n# print(formatted_data[72])","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:43.369944Z","iopub.execute_input":"2024-09-20T03:51:43.370334Z","iopub.status.idle":"2024-09-20T03:51:43.455886Z","shell.execute_reply.started":"2024-09-20T03:51:43.370290Z","shell.execute_reply":"2024-09-20T03:51:43.454789Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \nevaluation_data = []\n\nfor passage in (passage_test):\n    formatted_entry = (\n        \"<begin_of_text> \"\n        \"<start_header_id>passage<end_header_id> \" + passage.strip() + \" \"\n        \"<eom_id> \"\n        \"<start_header_id>questions<end_header_id>\" \n        \"<eot_id> \"\n        \"<end_of_text>\"\n    )\n    evaluation_data.append(formatted_entry)\n\n# print(evaluation_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:51:43.459609Z","iopub.execute_input":"2024-09-20T03:51:43.460197Z","iopub.status.idle":"2024-09-20T03:51:43.525947Z","shell.execute_reply.started":"2024-09-20T03:51:43.460142Z","shell.execute_reply":"2024-09-20T03:51:43.524956Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",  # You can choose \"fp4\" or \"nf4\"\n    bnb_4bit_use_double_quant=True,  # Optional: Use double quantization for better precision\n    bnb_4bit_compute_dtype=\"float16\"  # Set compute to float16 to save memory\n)\n\n# Load the model with the new quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,  # Use BitsAndBytesConfig for quantization\n    device_map='auto'  # Automatically map the model to available devices (e.g., GPU)\n)\n\n# Apply LoRA (Low-Rank Adaptation)\nlora_config = LoraConfig(\n    r=8,  # Low-rank dimension\n    lora_alpha=32,  # Scaling factor\n    lora_dropout=0.1,  # Dropout for LoRA layers\n    target_modules=[\"q_proj\", \"v_proj\"]  # Target layers for LoRA adaptation\n)\n\n# Wrap the model with QLoRA (Quantized Low-Rank Adaptation)\nmodel = get_peft_model(model, lora_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:52:10.618342Z","iopub.execute_input":"2024-09-20T03:52:10.619197Z","iopub.status.idle":"2024-09-20T03:53:38.976818Z","shell.execute_reply.started":"2024-09-20T03:52:10.619153Z","shell.execute_reply":"2024-09-20T03:53:38.976010Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926855a673cf4e82ad888162f4953318"}},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 2.1 ******************************* \nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-3.1/transformers/8b-instruct/2/\")\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:53:38.978399Z","iopub.execute_input":"2024-09-20T03:53:38.978705Z","iopub.status.idle":"2024-09-20T03:53:39.450606Z","shell.execute_reply.started":"2024-09-20T03:53:38.978673Z","shell.execute_reply":"2024-09-20T03:53:39.449524Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 3 ******************************* \nfrom torch.utils.data import Dataset\n\nclass TextGenerationDataset(Dataset):\n    def __init__(self, formatted_data, tokenizer, max_length=1024):\n        self.formatted_data = formatted_data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.formatted_data)\n\n    def __getitem__(self, idx):\n        # Get the formatted entry\n        formatted_entry = self.formatted_data[idx]\n        \n        \n        # Tokenize the entire formatted entry\n        encoding = self.tokenizer(\n            formatted_entry,\n            return_tensors='pt',\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True\n        )\n\n        # Extract input_ids and create labels\n        input_ids = encoding['input_ids'].squeeze()\n        labels = input_ids.clone() \n\n        return {'input_ids': input_ids, 'labels': labels}\n\n# Prepare the dataset using the new formatted data\ntrain_dataset = TextGenerationDataset(train_data, tokenizer)\ntest_dataset =  TextGenerationDataset(evaluation_data, tokenizer)\n\n# Define the DataLoader if needed\n# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:57:50.717775Z","iopub.execute_input":"2024-09-20T03:57:50.718168Z","iopub.status.idle":"2024-09-20T03:57:50.727134Z","shell.execute_reply.started":"2024-09-20T03:57:50.718129Z","shell.execute_reply":"2024-09-20T03:57:50.726154Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# ******************************* 3.1 ******************************* \nimport torch\nprint(torch.cuda.device_count())  ","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:57:52.213326Z","iopub.execute_input":"2024-09-20T03:57:52.213655Z","iopub.status.idle":"2024-09-20T03:57:52.218821Z","shell.execute_reply.started":"2024-09-20T03:57:52.213623Z","shell.execute_reply":"2024-09-20T03:57:52.217858Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 3.2 ******************************* \nimport torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:57:52.388054Z","iopub.execute_input":"2024-09-20T03:57:52.388354Z","iopub.status.idle":"2024-09-20T03:57:52.392566Z","shell.execute_reply.started":"2024-09-20T03:57:52.388322Z","shell.execute_reply":"2024-09-20T03:57:52.391698Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Verify the type of datasets\nprint(type(train_dataset))\nprint(type(test_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:57:52.566921Z","iopub.execute_input":"2024-09-20T03:57:52.567190Z","iopub.status.idle":"2024-09-20T03:57:52.571962Z","shell.execute_reply.started":"2024-09-20T03:57:52.567160Z","shell.execute_reply":"2024-09-20T03:57:52.570984Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<class '__main__.TextGenerationDataset'>\n<class '__main__.TextGenerationDataset'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_dataset))\n\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-20T03:57:53.701895Z","iopub.execute_input":"2024-09-20T03:57:53.702211Z","iopub.status.idle":"2024-09-20T03:57:53.707427Z","shell.execute_reply.started":"2024-09-20T03:57:53.702180Z","shell.execute_reply":"2024-09-20T03:57:53.706408Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"100\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 4 ******************************* \nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Define training arguments for multi-GPU and FP16\ntraining_args = TrainingArguments(\n    output_dir='./results_1',\n    num_train_epochs=3,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    save_steps=100,\n    save_total_limit=1,\n    logging_dir='./logs',\n    report_to='none',  # optional: to avoid logging issues with multiple GPUs\n    ddp_find_unused_parameters=True,  # required for multi-GPU\n    fp16=True,  \n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator\n    )\n\n# Fine-tune the model\ntrainer.train()\n\n# eval_results = trainer.evaluate(eval_dataset=eval_dataset)\n# print(f\"BLEU score: {eval_results['eval_bleu']}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-20T04:01:05.012278Z","iopub.execute_input":"2024-09-20T04:01:05.012695Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 30/300 01:15 < 12:05, 0.37 it/s, Epoch 0.29/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    save_steps=10_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n)\n\n# Fine-tune the model\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-19T16:02:06.351757Z","iopub.status.idle":"2024-09-19T16:02:06.352173Z","shell.execute_reply.started":"2024-09-19T16:02:06.351956Z","shell.execute_reply":"2024-09-19T16:02:06.351976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaTokenizer\n\n# Load the tokenizer\ntokenizer = LlamaTokenizer.from_pretrained('path/to/llama-3.1')\n\n# Tokenize each formatted entry\ntokenized_data = [tokenizer(entry, return_tensors='pt', padding='max_length', truncation=True) for entry in formatted_data]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pre-processing\n\ndef preprocess_data(row):\n    passage = row['passage']\n    mcqs = row['mcqs']\n    # Combine the passage and questions into a single text\n    combined_text = f\"{passage}\\n\\n{mcqs}\"\n    return combined_text\n\n# Apply the preprocessing function\ndf['combined_text'] = df.apply(preprocess_data, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df['combined_text'][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = pipeline.tokenizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    tokenizer.pad_token = '[PAD]'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert your DataFrame to a Hugging Face Dataset\ndataset = Dataset.from_pandas(df)\n\n# Define your tokenize_function\ndef tokenize_function(examples):\n    inputs = tokenizer(examples[\"combined_text\"], padding=\"max_length\", truncation=True, max_length=512)\n    return inputs\n\n# Apply the tokenize_function to the dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and validation sets\nsplit_dataset = tokenized_dataset.train_test_split(test_size=0.2)\ntrain_dataset = split_dataset['train']\nval_dataset = split_dataset['test']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, load_metric","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer, AutoTokenizer, DataCollatorForSeq2Seq\n\n# Data Collator\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=pipeline.model)\n\n# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    report_to=None,\n    eval_strategy=\"steps\",\n    learning_rate=1e-4,\n    per_device_train_batch_size=1,\n    num_train_epochs=50,\n    weight_decay=0.01,\n    logging_steps=10,\n    fp16=True,\n    gradient_checkpointing=True,\n)\n\n# Trainer\ntrainer = Trainer(\n    model=pipeline.model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\n# Training\ntrainer.train()\n\n# Evaluate\neval_results = trainer.evaluate()\nprint(f\"BLEU score: {eval_results['eval_bleu']}\")\n\n# Save the model\n# pipeline.model.save_pretrained(\"./fine-tuned-llama\")\n# tokenizer.save_pretrained(\"./fine-tuned-llama\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}