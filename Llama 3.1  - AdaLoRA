{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9401942,"sourceType":"datasetVersion","datasetId":5707438},{"sourceId":104449,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ******************************* 0 ******************************* \n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-25T08:05:56.276863Z","iopub.execute_input":"2024-09-25T08:05:56.277701Z","iopub.status.idle":"2024-09-25T08:05:56.641207Z","shell.execute_reply.started":"2024-09-25T08:05:56.277650Z","shell.execute_reply":"2024-09-25T08:05:56.640379Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/combined-data/combines_dataset.csv\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n","output_type":"stream"}]},{"cell_type":"code","source":"# Necessary until transformers package is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel = \"/kaggle/input/llama-3.1/transformers/8b/1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = transformers.pipeline(\n    \"text-generation\", model=model,max_length = 2048, model_kwargs={\"torch_dtype\": torch.bfloat16}, device_map=\"auto\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline('''Generate 15 MCQs from the following passage of different difficulty levels. \nThe questions should be of easy, medium and hard difficulty level, where each difficulty level should have 5 questions each.\nHorticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.\n''',max_length = 2048)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Llama 3.1 8B-Instruct","metadata":{}},{"cell_type":"code","source":"passage = '''Horticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are an assitant social studies teacher in a High School.\"},\n    {\"role\": \"user\", \"content\": prompt + passage},\n]\n\noutputs = pipeline(\n    messages,\n    max_new_tokens=2048,\n)\nprint(outputs[0][\"generated_text\"][-1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generated MCQS on ","metadata":{}},{"cell_type":"markdown","source":"\"**Section 1: Recall (Easy Difficulty Level)**\\n\\n1. What is Horticulture?\\n   a) Growing vegetables, flowers and fruits for commercial use\\n   b) Farming for subsistence\\n   c) Farming for commercial use\\n   d) Growing crops for household use\\n\\nAnswer: a) Growing vegetables, flowers and fruits for commercial use\\n\\n2. What are the important inputs in a farm system?\\n   a) Seeds, fertilisers, machinery and labour\\n   b) Seeds, fertilisers, animals and soil\\n   c) Seeds, labour, machinery and water\\n   d) Seeds, fertilisers, animals and tools\\n\\nAnswer: a) Seeds, fertilisers, machinery and labour\\n\\n3. What are the outputs from a farm system?\\n   a) Crops, wool, dairy and poultry products\\n   b) Crops, seeds, fertilisers and labour\\n   c) Crops, animals, tools and water\\n   d) Crops, animals, seeds and soil\\n\\nAnswer: a) Crops, wool, dairy and poultry products\\n\\n4. What is subsistence farming?\\n   a) Farming to meet the needs of the farmer's family\\n   b) Farming for commercial use\\n   c) Farming for household use\\n   d) Farming for export\\n\\nAnswer: a) Farming to meet the needs of the farmer's family\\n\\n5. What is intensive subsistence agriculture?\\n   a) Farming using simple tools and more labour\\n   b) Farming using complex tools and less labour\\n   c) Farming using animals and household labour\\n   d) Farming using machines and commercial labour\\n\\nAnswer: a) Farming using simple tools and more labour\\n\\n\n**Section 2: Analyze (Medium Difficulty Level)**\\n\\n6. What are the geographical conditions that permit intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Large number of days with sunshine and fertile soils\\n   b) Heavy rainfall and quick regeneration of vegetation\\n   c) Semi-arid and arid regions\\n   d) Thickly populated areas\\n\\nAnswer: a) Large number of days with sunshine and fertile soils\\n\\n7. What are the main crops grown in intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Rice, wheat, maize, pulses and oilseeds\\n   b) Maize, yam, potatoes and cassava\\n   c) Sheep, camel, yak and goats\\n   d) Cattle, buffalo and horses\\n\\nAnswer: a) Rice, wheat, maize, pulses and oilseeds\\n\\n8. What is shifting cultivation? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Shifting from one plot of land to another\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Shifting from one plot of land to another\\n\\n9. What is nomadic herding? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Moving from place to place with animals for fodder and water\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n10. What are the products provided by sheep, camel, yak and goats in nomadic herding? (Bloom's Taxonomy: Analyze)\\n    a) Milk, meat, wool, hides and other products\\n    b) Crops, seeds, fertilisers and labour\\n    c) Crops, animals, tools and water\\n    d) Crops, animals, seeds and soil\\n\\nAnswer: a) Milk, meat, wool, hides and other products\\n\\n\n**Section 3: Evaluate (Hard Difficulty Level)**\\n\\n11. What are the limitations of subsistence farming? (Bloom's Taxonomy: Evaluate)\\n    a) Low levels of technology and household labour\\n    b) High levels of technology and commercial labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Low levels of technology and household labour\\n\\n12. What are the advantages of intensive subsistence agriculture? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: c) Large number of days with sunshine and fertile soils\\n\\n13. What are the limitations of shifting cultivation? (Bloom's Taxonomy: Evaluate)\\n    a) Soil loses its fertility and is abandoned\\n    b) Soil retains its fertility and is reused\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Soil loses its fertility and is abandoned\\n\\n14. What are the advantages of nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Moving from place to place with animals for fodder and water\\n    d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n15. What are the geographical conditions that permit nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) Large number of days with sunshine and fertile soils\\n    b) Heavy rainfall and quick regeneration of vegetation\\n    c) Semi-arid and arid regions\\n    d) Thickly populated areas\\n\\nAnswer: c) Semi-arid and arid regions\"}","metadata":{}},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{}},{"cell_type":"markdown","source":"## Using ADALORA\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 0.1 ******************************* \n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:04.292738Z","iopub.execute_input":"2024-09-25T08:06:04.293558Z","iopub.status.idle":"2024-09-25T08:06:23.370675Z","shell.execute_reply.started":"2024-09-25T08:06:04.293518Z","shell.execute_reply":"2024-09-25T08:06:23.369733Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.2 ******************************* \nimport bitsandbytes as bnb\nprint(bnb.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:23.372671Z","iopub.execute_input":"2024-09-25T08:06:23.372989Z","iopub.status.idle":"2024-09-25T08:06:26.607288Z","shell.execute_reply.started":"2024-09-25T08:06:23.372953Z","shell.execute_reply":"2024-09-25T08:06:26.606395Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"0.44.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.3 ******************************* \n!pip install transformers\n!pip install peft  # This is for Parameter-Efficient Fine-Tuning (PEFT)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:26.608743Z","iopub.execute_input":"2024-09-25T08:06:26.609713Z","iopub.status.idle":"2024-09-25T08:06:53.048544Z","shell.execute_reply.started":"2024-09-25T08:06:26.609663Z","shell.execute_reply":"2024-09-25T08:06:53.047614Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.051727Z","iopub.execute_input":"2024-09-25T08:06:53.052098Z","iopub.status.idle":"2024-09-25T08:06:53.056987Z","shell.execute_reply.started":"2024-09-25T08:06:53.052061Z","shell.execute_reply":"2024-09-25T08:06:53.055840Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\n\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = pipeline.model","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adalora\n\nfrom peft import AdaLoraConfig, AdaLoraModel\n\nadalora_config = AdaLoraConfig(\n    task_type=\"CAUSAL_LM\",\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\n\nmodel = AdaLoraModel(model, adalora_config, \"default\")\n\n# number of trainable parameters\nnum_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n#total number of parameters\ntotal_params = sum(p.numel() for p in model.parameters())\n\n# percentage of trainable parameters\npercentage_trainable_params = (num_trainable_params / total_params) * 100\n\nprint(\"Number of trainable parameters:\", num_trainable_params)\nprint(\"Total number of parameters:\", total_params)\nprint(\"Percentage of trainable parameters:\", percentage_trainable_params)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading dataset","metadata":{}},{"cell_type":"code","source":"# ******************************* 1 ******************************* \nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/combined-data/combines_dataset.csv', encoding='ISO-8859-1')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.058212Z","iopub.execute_input":"2024-09-25T08:06:53.058591Z","iopub.status.idle":"2024-09-25T08:06:53.137806Z","shell.execute_reply.started":"2024-09-25T08:06:53.058550Z","shell.execute_reply":"2024-09-25T08:06:53.136887Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.1 ******************************* \n# Display the first few rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.139051Z","iopub.execute_input":"2024-09-25T08:06:53.139495Z","iopub.status.idle":"2024-09-25T08:06:53.159840Z","shell.execute_reply.started":"2024-09-25T08:06:53.139443Z","shell.execute_reply":"2024-09-25T08:06:53.158998Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             passage  \\\n0  This transformation from a plant to a finished...   \n1  People are a nationâs greatest resource. Nat...   \n2  Have you ever given a thought to the fact that...   \n3  In a small village in Tanzania, Africa, Mamba ...   \n4  Water, electricity, rickshaw, vegetable and te...   \n\n                                                mcqs  \n0  ['## Agriculture and Economic Activities: An M...  \n1  ['## Population Studies Test\\n', '\\n', '**Inst...  \n2  ['## The Journey of Your Notebook: A Social St...  \n3  ['## Social Studies Test: Land as a Resource\\n...  \n4  ['## Agriculture and Farming: An MCQ Test\\n', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passage</th>\n      <th>mcqs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This transformation from a plant to a finished...</td>\n      <td>['## Agriculture and Economic Activities: An M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>People are a nationâs greatest resource. Nat...</td>\n      <td>['## Population Studies Test\\n', '\\n', '**Inst...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Have you ever given a thought to the fact that...</td>\n      <td>['## The Journey of Your Notebook: A Social St...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In a small village in Tanzania, Africa, Mamba ...</td>\n      <td>['## Social Studies Test: Land as a Resource\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Water, electricity, rickshaw, vegetable and te...</td>\n      <td>['## Agriculture and Farming: An MCQ Test\\n', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \n# Import the splitting function\nfrom sklearn.model_selection import train_test_split\n\n# Split the formatted data into training and testing sets\ntrain_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n\n# Check the lengths of the train and test splits\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Testing set size: {len(test_data)}\")\n\n# Optional: Print the first entry from the training and test set\nprint(f\"First training example: {train_data.iloc[0]}\")\nprint(len(train_data),\"\\n\")\nprint(f\"First testing example: {test_data.iloc[0]}\")\nprint(len(test_data))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.160905Z","iopub.execute_input":"2024-09-25T08:06:53.161176Z","iopub.status.idle":"2024-09-25T08:06:53.717259Z","shell.execute_reply.started":"2024-09-25T08:06:53.161145Z","shell.execute_reply":"2024-09-25T08:06:53.716314Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training set size: 100\nTesting set size: 43\nFirst training example: passage    European Imperialism The American empires of S...\nmcqs       ['## European Imperialism - MCQ Test\\n', '\\n',...\nName: 84, dtype: object\n100 \n\nFirst testing example: passage    1. A Mosaic of Religious Beliefs and Practices...\nmcqs       ['## MCQ Test: A Mosaic of Religious Beliefs\\n...\nName: 117, dtype: object\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.718313Z","iopub.execute_input":"2024-09-25T08:06:53.718790Z","iopub.status.idle":"2024-09-25T08:06:53.723842Z","shell.execute_reply.started":"2024-09-25T08:06:53.718753Z","shell.execute_reply":"2024-09-25T08:06:53.722785Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"passages = train_data['passage'].tolist()\nmcqs = train_data['mcqs'].tolist()\n\npassage_test = test_data['passage'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.725063Z","iopub.execute_input":"2024-09-25T08:06:53.725455Z","iopub.status.idle":"2024-09-25T08:06:53.733823Z","shell.execute_reply.started":"2024-09-25T08:06:53.725418Z","shell.execute_reply":"2024-09-25T08:06:53.732810Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## New Prompt\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n\n<|start_header_id|>User<|end_header_id|>\npassage<|eot_id|>\n\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nmcqs<|eot_id|>\n\n<|end_of_text|>\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 1.2 ******************************* \ntrain_data = []\n\nfor passage, mcq in zip(passages, mcqs):\n    formatted_entry = f'''\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n<|start_header_id|>User<|end_header_id|>\n{passage} <|eot_id|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\n{mcq}<|eot_id|>\n<|end_of_text|>\n'''\n    train_data.append(formatted_entry)\n\nprint(train_data[72])","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.736264Z","iopub.execute_input":"2024-09-25T08:06:53.736599Z","iopub.status.idle":"2024-09-25T08:06:53.744488Z","shell.execute_reply.started":"2024-09-25T08:06:53.736557Z","shell.execute_reply":"2024-09-25T08:06:53.743660Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n<|start_header_id|>User<|end_header_id|>\nNineteenth-century Europeans were very interested in the stupa at Sanchi. In fact, the French\nsought Shahjehan Begumâs permission to take away the eastern gateway, which was the best\npreserved, to be displayed in a museum in France. For a while some Englishmen also wanted\nto do the same, but fortunately both the French and the English were satisfied with carefully\nprepared plaster-cast copies and the original remained at the site, part of the Bhopal state. The\nrulers of Bhopal, Shahjehan Begum and her successor Sultan Jehan Begum, provided money\nfor the preservation of the ancient site. No wonder then that John Marshall dedicated his\nimportant volumes on Sanchi to Sultan Jehan. She funded the museum that was built there as\nwell as the guesthouse where he lived and wrote the volumes. She also funded the publication\nof the volumes. So if the stupa complex has survived, it is in no small measure due to wise\ndecisions, and to good luck in escaping the eyes of railway contractors, builders, and those\nlooking for finds to carry away to the museums of Europe. One of the most important Buddhist\ncentres, the discovery of Sanchi has vastly transformed our understanding of early Buddhism.\nToday it stands testimony to the successful restoration and preservation of a key archaeological\nsite by the Archaeological Survey of India.But what is the significance of this monument? Why\nwas the mound built and what did it contain? Why is there a stone railing around it? Who built\nthe complex or paid for its construction? When was it âdiscoveredâ? There is a fascinating story\nthat we can uncover at Sanchi for which we must combine information from texts, sculpture,\narchitecture and inscriptions. Let us begin by exploring the background of the early Buddhist\ntradition.\n2. The Background: Sacrifices and Debates\nThe mid-first millennium BCE is often regarded as a turning point in world history: it saw the\nemergence of thinkers such as Zarathustra in Iran, Kong Zi in China, Socrates, Plato and\nAristotle in Greece, and Mahavira and Gautama Buddha, among many others, in India. They\ntried to understand the mysteries of existence and the relationship between human beings and\nthe cosmic order. This was also the time when new kingdoms and cities were developing and\nsocial and economic life was changing in a variety of ways in the Ganga valley (Chapters 2 and\n3). These thinkers attempted to understand these developments as well.\n2.1 The sacrificial tradition\nThere were several pre-existing traditions of thought, religious belief and practice, including the\nearly Vedic tradition, known from the Rigveda, compiled between c.1500 and 1000 BCE. The\nRigveda consists of hymns in praise of a variety of deities, especially Agni, Indra and Soma.\nMany of these hymns were chanted when sacrifices were performed, where people prayed for\ncattle, sons, good health, long life, etc. At first, sacrifices were performed collectively. Later (c.\n1000 BCE-500 BCE onwards) some were performed by the heads of households for the\nwellbeing of the domestic unit. More elaborate sacrifices, such as the rajasuya and\nashvamedha, were performed by chiefs and kings who depended on Brahmana priests to\nconduct the ritual.\n2.2 New questions\nMany ideas found in the Upanishads (c. sixth century BCE onwards) show that people were\ncurious about the meaning of life, the possibility of life after death,and rebirth. Was rebirth due to\npast actions? Such issues were hotly debated. Thinkers were concerned with understanding\nand expressing the nature of the ultimate reality. And others, outside the Vedic tradition, askedwhether or not there even was a single ultimate reality. People also began speculating on the\nsignificance of the sacrificial tradition.\n2.3 Debates and discussions\nWe get a glimpse of lively discussions and debates from Buddhist texts, which mention as many\nas 64 sects or schools of thought. Teachers travelled from place to place, trying to convince one\nanother as well as laypersons, about the validity of their philosophy or the way they understood\nthe world. Debates took place in the kutagarashala â literally, a hut with a pointed roof â or in\ngroves where travelling mendicants halted. If a philosopher succeeded in convincing one of his\nrivals, the followers of the latter also became his disciples. So support for any particular sect\ncould grow and shrink over time. Many of these teachers, including Mahavira and the Buddha,\nquestioned the authority of the Vedas. They also emphasised individual agency â suggesting\nthat men and women could strive to attain liberation from the trials and tribulations of worldly\nexistence. This was in marked contrast to the Brahmanical position, wherein, as we have seen,\nan individualâs existence was thought to be determined by his or her birth in a specific caste or\ngender.\n3.Beyond Worldly Pleasures\nThe Message of Mahavira The basic philosophy of the Jainas was already in existence in north\nIndia before the birth of Vardhamana, who came to be known as Mahavira, in the sixth century\nBCE. According to Jaina tradition, Mahavira was preceded by 23 other teachers or tirthankaras\nâ literally, those who guide men and women across the river of existence. The most important\nidea in Jainism is that the entire world is animated: even stones, rocks and water have life.\nNon-injury to living beings, especially to humans, animals, plants and insects, is central to Jaina\nphilosophy. In fact the principle of ahimsa, emphasised within Jainism, has left its mark on\nIndian thinking as a whole. According to Jaina teachings, the cycle of birth and rebirth is shaped\nthrough karma. Asceticism and penance are required to free oneself from the cycle of karma.\nThis can be achieved only by renouncing the world; therefore, monastic existence is a\nnecessary condition of salvation. Jaina monks and nuns took five vows: to abstain from killing,\nstealing and lying; to observe celibacy; and to abstain from possessing property.\n3.1 The spread of Jainism\nGradually, Jainism spread to many parts of India. Like the Buddhists, Jaina scholars produced a\nwealth of literature in a variety of languages â Prakrit, Sanskrit and Tamil. For centuries,\nmanuscripts of these texts were carefully preserved in libraries attached to temples. Some of the\nearliest stone sculptures associated with religious traditions were produced by devotees of the\nJaina tirthankaras, and have been recovered from several sites throughout the subcontinent.\n4.The Buddha and the Quest for Enlightenment\nOne of the most influential teachers of the time was the Buddha. Over the centuries, his\nmessage spread across the subcontinent and beyond â through Central Asia to China, Korea\nand Japan, and through Sri Lanka, across the seas to Myanmar, Thailand and Indonesia. How\ndo we know about the Buddhaâs teachings? These have been reconstructed by carefully editing,\ntranslating and analysing the Buddhist texts mentioned earlier. Historians have also tried to\nreconstruct details of his life from hagiographies. Many of these were written down at least a\ncentury after the time of the Buddha, in an attempt to preserve memories of the great teacher.\nAccording to these traditions, Siddhartha, as the Buddha was named at birth, was the son of a\nchief of the Sakya clan. He had a sheltered upbringing within the palace, insulated from theharsh realities of life. One day he persuaded his charioteer to take him into the city. His first\njourney into the world outside was traumatic. He was deeply anguished when he saw an old\nman, a sick man and a corpse. He realised in that moment that the decay and destruction of the\nhuman body was inevitable. He also saw a homeless mendicant, who, it seemed to him, had\ncome to terms with old age, disease and death, and found peace. Siddhartha decided that he\ntoo would adopt the same path. Soon after, he left the palace and set out in search of his own\ntruth. Siddhartha explored several paths including bodily mortification which led him to a\nsituation of near death. Abandoning these extreme methods, he meditated for several days and\nfinally attained enlightenment. After this he came to be known as the Buddha or the Enlightened\nOne. For the rest of his life, he taught dhamma or the path of righteous living. <|eot_id|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\n['## Sanchi Stupa and Early Buddhism: MCQ Test\\n', '\\n', '**Easy Level**\\n', '\\n', '**Q1:** What did the French and English initially want to do with the eastern gateway of the Sanchi stupa?\\n', '(A) Restore it\\n', '(B) Take it away\\n', '(C) Build a museum around it\\n', '(D) Sell it to a collector\\n', '\\n', '**Q2:** What is the central principle of Jainism?\\n', '(A) Ahimsa (non-injury)\\n', '(B) Karma\\n', '(C) Renunciation\\n', '(D) Asceticism\\n', '\\n', '**Q3:** Who funded the restoration of the Sanchi stupa and the construction of the museum and guesthouse?\\n', '(A) The British government\\n', '(B) Shahjehan Begum\\n', '(C) Sultan Jehan Begum\\n', '(D) John Marshall\\n', '\\n', '**Q4:** Which Indian thinker questioned the authority of the Vedas?\\n', '(A) Mahavira\\n', '(B) Zarathustra\\n', '(C) Socrates\\n', '(D) Aristotle\\n', '\\n', '**Q5:** What is the significance of the discovery of Sanchi?\\n', '(A) It revealed the existence of the Vedic tradition\\n', '(B) It transformed our understanding of early Buddhism\\n', '(C) It led to the construction of the Taj Mahal\\n', '(D) It proved the existence of dinosaurs\\n', '\\n', '\\n', '**Medium Level**\\n', '\\n', '**Q6:** What did Siddhartha realize after seeing an old man, a sick man, and a corpse?\\n', '(A) That life is meaningless\\n', '(B) That wealth and power are useless\\n', '(C) That the human body is impermanent and subject to decay\\n', '(D) That all humans are equal\\n', '\\n', '**Q7:** How did Siddhartha attain enlightenment?\\n', '(A) Through meditation\\n', '(B) Through prayer\\n', '(C) Through rigorous fasting\\n', '(D) Through the study of the Upanishads\\n', '\\n', '**Q8:** What is the name of the path of righteous living taught by the Buddha?\\n', '(A) Dhamma\\n', '(B) Karma\\n', '(C) Ahimsa\\n', '(D)Nirvana\\n', '\\n', '**Q9:** Why did Siddhartha leave the palace and set out in search of his own truth?\\n', '(A) To seek enlightenment\\n', '(B) To escape his royal duties\\n', \"(C) To find a cure for his father's illness\\n\", '(D) To avenge the death of his brother\\n', '\\n', '**Q10:**  Which of the following is NOT a sect or school of thought mentioned in the Buddhist texts?\\n', '(A) Brahmanas\\n', '(B) Upanishads\\n', '(C) Jains\\n', '(D) Charvakas\\n', '\\n', '**Hard Level**\\n', '\\n', '**Q11:**  What is the name of the earliest known compilation of hymns in the Vedic tradition?\\n', '(A) Bhagavad Gita\\n', '(B) Rigveda\\n', '(C) Upanishads\\n', '(D) Ramayana\\n', '\\n', '**Q12:** Why did the rulers of Bhopal, Shahjehan Begum and Sultan Jehan Begum, provide money for the preservation of the Sanchi stupa?\\n', '(A) They were devout Buddhists\\n', '(B) They wanted to attract tourists\\n', '(C) They believed it was their historical duty\\n', '(D) They sought to gain political favor\\n', '\\n', '**Q13:** What was the primary purpose of the kutagarashala?\\n', '(A) To conduct rituals\\n', '(B) To store religious texts\\n', '(C) To host debates and discussions\\n', '(D) To provide shelter for travelers\\n', '\\n', \"**Q14:** How do historians reconstruct details of the Buddha's life?\\n\", '(A) From contemporary letters and documents\\n', '(B) From hagiographies written decades after his death\\n', '(C) From archaeological evidence\\n', '(D) From oral tradition\\n', '\\n', '**Q15:** What is the significance of the stone railing around the Sanchi stupa?\\n', '(A) It protected the stupa from animals\\n', '(B) It marked the boundary of the sacred space\\n', '(C) It prevented people from touching the relics inside\\n', '(D) It was used for religious ceremonies\\n', '\\n', '## Answer Key\\n', '\\n', '**Easy Level**\\n', '\\n', '**Q1:** B \\n', '**Q2:** A\\n', '**Q3:** C\\n', '**Q4:** A\\n', '**Q5:** B\\n', '\\n', '**Medium Level**\\n', '\\n', '**Q6:** C\\n', '**Q7:** A\\n', '**Q8:** A\\n', '**Q9:** A\\n', '**Q10:** B\\n', '\\n', '**Hard Level**\\n', '\\n', '**Q11:** B\\n', '**Q12:** C\\n', '**Q13:** C\\n', '**Q14:** B\\n', '**Q15:** B \\n']<|eot_id|>\n<|end_of_text|>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \nevaluation_data = []\n\nfor passage in (passage_test):\n    formatted_entry =  f'''\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n<|start_header_id|>User<|end_header_id|>\n{passage} <|eot_id|>\n<|end_of_text|>\n'''\n\n\n    evaluation_data.append(formatted_entry)\n\n# print(evaluation_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.745618Z","iopub.execute_input":"2024-09-25T08:06:53.745985Z","iopub.status.idle":"2024-09-25T08:06:53.752060Z","shell.execute_reply.started":"2024-09-25T08:06:53.745939Z","shell.execute_reply":"2024-09-25T08:06:53.751108Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",  # You can choose \"fp4\" or \"nf4\"\n    bnb_4bit_use_double_quant=True,  # Optional: Use double quantization for better precision\n    bnb_4bit_compute_dtype=\"float16\"  # Set compute to float16 to save memory\n)\n\n# Load the model with the new quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,  # Use BitsAndBytesConfig for quantization\n    device_map='auto'  # Automatically map the model to available devices (e.g., GPU)\n)\n\n# Apply LoRA (Low-Rank Adaptation)\nlora_config = LoraConfig(\n    r=8,  # Low-rank dimension\n    lora_alpha=32,  # Scaling factor\n    lora_dropout=0.1,  # Dropout for LoRA layers\n    target_modules=[\"q_proj\", \"v_proj\"]  # Target layers for LoRA adaptation\n)\n\n# Wrap the model with QLoRA (Quantized Low-Rank Adaptation)\nmodel = get_peft_model(model, lora_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:06:53.753455Z","iopub.execute_input":"2024-09-25T08:06:53.753871Z","iopub.status.idle":"2024-09-25T08:08:13.021475Z","shell.execute_reply.started":"2024-09-25T08:06:53.753826Z","shell.execute_reply":"2024-09-25T08:08:13.020639Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18279bf897944381a028b659f1117d2d"}},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 2.1 ******************************* \nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-3.1/transformers/8b-instruct/2/\")\ntokenizer.add_special_tokens({\n    'pad_token': '[PAD]',\n    'additional_special_tokens': ['<|begin_of_text|>', '<|start_header_id|>', '<|end_header_id|>', '<|eom_id|>', '<|eot_id|>', '<|end_of_text|>']\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:19.659871Z","iopub.execute_input":"2024-09-25T08:08:19.660465Z","iopub.status.idle":"2024-09-25T08:08:20.143117Z","shell.execute_reply.started":"2024-09-25T08:08:19.660425Z","shell.execute_reply":"2024-09-25T08:08:20.142198Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:20.394998Z","iopub.execute_input":"2024-09-25T08:08:20.396081Z","iopub.status.idle":"2024-09-25T08:08:20.495214Z","shell.execute_reply.started":"2024-09-25T08:08:20.396029Z","shell.execute_reply":"2024-09-25T08:08:20.494355Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Embedding(128257, 4096)"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 3 ******************************* \nfrom torch.utils.data import Dataset\n\nclass TextGenerationDataset(Dataset):\n    def __init__(self, formatted_data, tokenizer, max_length=1024):\n        self.formatted_data = formatted_data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.formatted_data)\n\n    def __getitem__(self, idx):\n        # Get the formatted entry\n        formatted_entry = self.formatted_data[idx]\n        \n        \n        # Tokenize the entire formatted entry\n        encoding = self.tokenizer(\n            formatted_entry,\n            return_tensors='pt',\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True\n        )\n\n        # Extract input_ids and create labels\n        input_ids = encoding['input_ids'].squeeze()\n        labels = input_ids.clone() \n\n        return {'input_ids': input_ids, 'labels': labels}\n\n# Prepare the dataset using the new formatted data\ntrain_dataset = TextGenerationDataset(train_data, tokenizer)\ntest_dataset =  TextGenerationDataset(evaluation_data, tokenizer)\n\n# Define the DataLoader if needed\n# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:26.414765Z","iopub.execute_input":"2024-09-25T08:08:26.415143Z","iopub.status.idle":"2024-09-25T08:08:26.423604Z","shell.execute_reply.started":"2024-09-25T08:08:26.415105Z","shell.execute_reply":"2024-09-25T08:08:26.422587Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# ******************************* 3.1 ******************************* \nimport torch\nprint(torch.cuda.device_count())  \ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:29.379700Z","iopub.execute_input":"2024-09-25T08:08:29.380546Z","iopub.status.idle":"2024-09-25T08:08:29.385429Z","shell.execute_reply.started":"2024-09-25T08:08:29.380505Z","shell.execute_reply":"2024-09-25T08:08:29.384515Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Verify the type of datasets\nprint(type(train_dataset))\nprint(type(test_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:29.561708Z","iopub.execute_input":"2024-09-25T08:08:29.562485Z","iopub.status.idle":"2024-09-25T08:08:29.566846Z","shell.execute_reply.started":"2024-09-25T08:08:29.562449Z","shell.execute_reply":"2024-09-25T08:08:29.566019Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class '__main__.TextGenerationDataset'>\n<class '__main__.TextGenerationDataset'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(train_dataset))\n\nprint(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:30.339458Z","iopub.execute_input":"2024-09-25T08:08:30.339771Z","iopub.status.idle":"2024-09-25T08:08:30.344469Z","shell.execute_reply.started":"2024-09-25T08:08:30.339740Z","shell.execute_reply":"2024-09-25T08:08:30.343604Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"100\n43\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\nbleu_metric = load_metric(\"bleu\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.split() for pred in decoded_preds]\n    decoded_labels = [[label.split()] for label in decoded_labels]  # BLEU expects a list of references for each prediction\n    \n    bleu_score = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": bleu_score['bleu']}","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:08:32.996286Z","iopub.execute_input":"2024-09-25T08:08:32.996932Z","iopub.status.idle":"2024-09-25T08:08:36.194953Z","shell.execute_reply.started":"2024-09-25T08:08:32.996893Z","shell.execute_reply":"2024-09-25T08:08:36.194201Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/1138584447.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  bleu_metric = load_metric(\"bleu\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62c786ec3005442bbe89b965b9d11174"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f40fa905d14d1fa5e87b1874ab0160"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for bleu contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bleu.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"}]},{"cell_type":"code","source":"# ******************************* 4 ******************************* \nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Define training arguments for multi-GPU and FP16\ntraining_args = TrainingArguments(\n    output_dir='./results_1',\n    num_train_epochs=10,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    save_steps=500,\n    save_total_limit=1,\n    logging_dir='./logs',\n    report_to='none',          # optional: to avoid logging issues with multiple GPUs\n    ddp_find_unused_parameters=True,  # required for multi-GPU\n    fp16=True,  \n    evaluation_strategy=\"epoch\", # new addition\n    save_strategy=\"epoch\"        # new addition\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n    )\n\n# Fine-tune the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T08:21:36.250589Z","iopub.execute_input":"2024-09-25T08:21:36.250977Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  54/1000 01:58 < 35:50, 0.44 it/s, Epoch 0.53/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Save the fine-tuned Model","metadata":{}},{"cell_type":"code","source":"# Save the final model, tokenizer, and training arguments\ntrainer.save_model(\"/kaggle/working/l\") \ntokenizer.save_pretrained(\"/kaggle/working/\")  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation on SuperGlue Score","metadata":{}},{"cell_type":"code","source":"\nprint(torch.cuda.device_count())  # Check number of GPUs available\nprint(torch.cuda.get_device_name(1))  # Check the name of the second GPU\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:20:52.848001Z","iopub.execute_input":"2024-09-25T06:20:52.849040Z","iopub.status.idle":"2024-09-25T06:20:52.854088Z","shell.execute_reply.started":"2024-09-25T06:20:52.848994Z","shell.execute_reply":"2024-09-25T06:20:52.853046Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"2\nTesla T4\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:17:59.107507Z","iopub.execute_input":"2024-09-25T06:17:59.107925Z","iopub.status.idle":"2024-09-25T06:18:11.897519Z","shell.execute_reply.started":"2024-09-25T06:17:59.107886Z","shell.execute_reply":"2024-09-25T06:18:11.896317Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('super_glue', 'boolq') ","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:18:11.900102Z","iopub.execute_input":"2024-09-25T06:18:11.900551Z","iopub.status.idle":"2024-09-25T06:18:13.199506Z","shell.execute_reply.started":"2024-09-25T06:18:11.900502Z","shell.execute_reply":"2024-09-25T06:18:13.198560Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:24:04.947238Z","iopub.execute_input":"2024-09-25T06:24:04.947982Z","iopub.status.idle":"2024-09-25T06:24:05.991996Z","shell.execute_reply.started":"2024-09-25T06:24:04.947935Z","shell.execute_reply":"2024-09-25T06:24:05.990794Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:23:15.214037Z","iopub.execute_input":"2024-09-25T06:23:15.214953Z","iopub.status.idle":"2024-09-25T06:23:15.298051Z","shell.execute_reply.started":"2024-09-25T06:23:15.214910Z","shell.execute_reply":"2024-09-25T06:23:15.296932Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\n# Load the BoolQ dataset and metric\nboolq_dataset = load_dataset('super_glue', 'boolq', split='validation')\naccuracy_metric = load_metric('accuracy')\n\ndevice = torch.device(\"cuda:0\")\nmodel = model.to(device)\n# Evaluate the model\npredictions = []\nfor example in boolq_dataset:\n    input_text = tokenizer(evaluation_data, return_tensors=\"pt\", padding=True, truncation=True)\n    input_ids = input_text[\"input_ids\"]\n    attention_mask = input_text[\"attention_mask\"]\n\n    # Run the model with the extracted input_ids and attention_mask\n    predicted_label = model(input_ids=input_ids, attention_mask=attention_mask)\n    predictions.append(predicted_label)\n\n# Calculate accuracy\naccuracy = accuracy_metric.compute(predictions=predictions, references=boolq_dataset['label'])\nprint(f\"BoolQ accuracy: {accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-25T06:24:10.793739Z","iopub.execute_input":"2024-09-25T06:24:10.794543Z","iopub.status.idle":"2024-09-25T06:24:12.494096Z","shell.execute_reply.started":"2024-09-25T06:24:10.794500Z","shell.execute_reply":"2024-09-25T06:24:12.492675Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m accuracy_metric \u001b[38;5;241m=\u001b[39m load_metric(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (4 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:338\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    337\u001b[0m new_param \u001b[38;5;241m=\u001b[39m Params4bit(\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    339\u001b[0m     requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad,\n\u001b[1;32m    340\u001b[0m     quant_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state,\n\u001b[1;32m    341\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize,\n\u001b[1;32m    342\u001b[0m     compress_statistics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress_statistics,\n\u001b[1;32m    343\u001b[0m     quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_type,\n\u001b[1;32m    344\u001b[0m     quant_storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_storage,\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_param\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 4522 has 14.73 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 25.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 4522 has 14.73 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 25.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"markdown","source":"# ________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# Example reference and candidate sentences\nreference = validation\ncandidate = test\n\n# Compute BLEU score with smoothing to avoid zero scores\nsmoothie = SmoothingFunction().method4\nbleu_score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n\nprint(f'BLEU score: {bleu_score:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Initialize an empty list to store evaluation results\neval_results = []\n\n# Set the small batch size for evaluation segments\nsmall_batch_size = 1  # Adjust as needed based on memory constraints\n\n# Create a DataLoader for the test dataset\neval_dataloader = DataLoader(test_dataset, batch_size=small_batch_size)\n\n# Evaluate the model on each small batch\nfor batch in eval_dataloader:\n    result = trainer.evaluation_loop(\n        dataloader=[batch],  # Pass the batch wrapped in a list\n        description=\"Evaluation\",\n        prediction_loss_only=True,  # Use if you don't want to compute other metrics\n    )\n\n    # Append the result for this batch to the list\n    eval_results.append(result)\n\n# Calculate the BLEU score by averaging over all batches\ntotal_bleu_score = sum(res['eval_bleu'] for res in eval_results if 'eval_bleu' in res) / len(eval_results)\n\n# Print the final BLEU score\nprint(f\"Final BLEU score: {total_bleu_score}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking: Trying the fine-tuned model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('/kaggle/working/path_to_save_model')\ntokenizer.save_pretrained('/kaggle/working/path_to_save_model')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"passage = '''This chapter deals with one of the most difficult challenges faced by independent India—poverty. After discussing this multi-dimensional problem through examples, the chapter discusses the way poverty is seen in social sciences. Poverty trends in India and the world are illustrated through the concept of the poverty line. Causes of poverty as well as anti-poverty measures taken by the government are also discussed. The chapter ends with broadening the official concept of poverty into human poverty. In our daily life, we come across many people who we think are poor. They could be landless labourers in villages or people living in overcrowded jhuggis in cities. They could be daily wage workers at construction sites or child workers in dhabas. They could also be beggars with children in tatters. We see poverty all around us. In fact, every fifth person in India is poor. (This means, roughly 270 million (or 27 crore) people in India live in poverty 2011-12.) This also means that India has the largest single concentration of the poor in the world. This illustrates the seriousness of the challenge. Urban Case Thirty-three year old Ram Saran works as a daily-wage labourer in a wheat flour mill near Ranchi in Jharkhand. He manages to earn around Rs 1,500 a month when he finds employment, which is not often. The money is not enough to sustain his family of six— that includes his wife and four children aged between 12 years to six months. He has to send money home to his old parents who live in a village near Ramgarh. His father a landless labourer, depends on Ram Saran and his brother who lives in Hazaribagh, for sustenance. Ram Saran lives in a one-room rented house in a crowded basti in the outskirts of the city. It’s a\ntemporary shack built of bricks and clay tiles. His wife Santa Devi, works as a part time maid in a few houses and manages to earn another Rs 800. They manage a meagre meal of dal and\nrice twice a day, but there’s never enough for all of them. His elder son works as a helper in a tea shop to supplement the family income and earns another Rs 300, while his 10- year-old daughter takes care of the younger siblings. None of the children go to school. They have only two pairs of hand-me-down clothes each. New ones are bought only when the old clothes become unwearable. Shoes are a luxury. The younger kids are undernourished. They have no access to healthcare when they fall ill. Rural case Lakha Singh belongs to a small village near Meerut in Uttar Pradesh. His family doesn’t own any land, so they do odd jobs for the big farmers. Work is erratic and so is income. At times they get paid Rs 50 for a hard day’s work. But often it’s in kind like a few kilograms of wheat or dal or even vegetables for toiling in the farm through the day. The family of eight cannot always manage two square meals a day. Lakha lives in a kuchha hut on the outskirts of the village. The women of the family spend the day chopping fodder and collecting firewood in the fields. His father a TB patient, passed away two years ago due to lack of medication. His mother now suffers from the same disease and life is slowly ebbing away.Although, the village has a primary school, Lakha never went there. He had to start earning when he was 10 years old. New clothes happen once in a few years. Even soap and oil are a luxury for the family. These two typical cases illustrate many dimensions of poverty. They show that poverty means hunger and lack of shelter. It also is a situation in which parents are\nnot able to send their children to school or a situation where sick people cannot afford treatment. Poverty also means lack of clean water and sanitation facilities. It also means lack of a regular job at a minimum decent level. Above all it means living with a sense of helplessness. Poor people are in a situation in which they are ill-treated at almost every place, in farms, factories, government offices, hospitals, railway stations etc. Obviously, nobody would like to live in poverty. One of the biggest challenges of independent India has been to bring millions of its people out of abject poverty. Mahatama Gandhi always insisted that India would be truly independent only when the poorest of its people become free of human suffering. Poverty as seen by social scientists Since poverty has many facets, social scientists look at it through a variety of indicators. Usually the indicators used relate to the levels of income and consumption. But now poverty is looked through other social indicators like illiteracy level, lack of general resistance due to malnutrition, lack of access to healthcare, lack of job opportunities, lack\nof access to safe drinking water, sanitation etc. Analysis of poverty based on social exclusion and vulnerability is now becoming very common.Social exclusion According to this concept, poverty must be seen in terms of the poor having to live only in a poor surrounding with other poor people, excluded from enjoying social equality of better-off people in better surroundings. Social exclusion can be both a cause as well as a consequence of poverty in the usual sense. Broadly, it is a process through which individuals or groups are excluded from facilities, benefits and opportunities that others (their “betters”) enjoy. A typical example is the working of the caste system in India in which people belonging to certain castes are excluded from equal opportunities. Social exclusion thus may lead to, but can cause more damage than, having a very low income. Vulnerability to poverty is a measure, which describes the greater\nprobability of certain communities (say, members of a backward caste) or individuals (such as a widow or a physically handicapped person) of becoming, or remaining, poor in the coming years. Vulnerability is determined by the options available to different communities for finding\nan alternative living in terms of assets, education, health and job opportunities. Further, it is analysed on the basis of the greater risks these groups face at the time of natural disasters (earthquakes, tsunami), terrorism etc. Additional analysis is made of their social and economic\nability to handle these risks. In fact, vulnerability describes the greater probability of being more adversely affected than other people when bad time comes for everybody, whether a\nflood or an earthquake or simply a fall in the availability of jobs!\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\n\n# Load the tokenizer first\ntokenizer = AutoTokenizer.from_pretrained('/kaggle/working/path_to_save_model')\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=\"float16\"\n)\n\n# Load the model with quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    '/kaggle/working/path_to_save_model',\n    quantization_config=quantization_config,\n    device_map='auto'\n)\n\n# Resize the model's token embeddings to match the tokenizer\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Define the LoRA configuration\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"q_proj\", \"v_proj\"]\n)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Example inference\ninput_text = passage\ninput_ids = tokenizer.encode(input_text, return_tensors='pt')\n\n# Generate text\nwith torch.no_grad():\n    generated_ids = model.generate(input_ids, max_length=150, pad_token_id=tokenizer.eos_token_id)\n\n# Decode the generated text\ngenerated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}