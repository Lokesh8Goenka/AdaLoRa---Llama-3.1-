{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9401942,"sourceType":"datasetVersion","datasetId":5707438},{"sourceId":104449,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102},{"sourceId":124809,"sourceType":"modelInstanceVersion","modelInstanceId":105041,"modelId":129263}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ******************************* 0 ******************************* \n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T05:54:46.997793Z","iopub.execute_input":"2024-10-04T05:54:46.998680Z","iopub.status.idle":"2024-10-04T05:54:47.409669Z","shell.execute_reply.started":"2024-10-04T05:54:46.998639Z","shell.execute_reply":"2024-10-04T05:54:47.408632Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n/kaggle/input/combined-data/combines_dataset.csv\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/adapter_model.safetensors\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/config.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/training_args.bin\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/adapter_config.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/README.md\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/tokenizer.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/tokenizer_config.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/special_tokens_map.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/lora/adapter_model.safetensors\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/lora/adapter_config.json\n/kaggle/input/llama3.1_15_epoch/transformers/v1/2/lora/README.md\n","output_type":"stream"}]},{"cell_type":"code","source":"# Necessary until transformers package is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel = \"/kaggle/input/llama-3.1/transformers/8b/1\"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Llama 3.1 8B-Instruct","metadata":{}},{"cell_type":"code","source":"prompt = '''Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. \n'''\npassage = '''Horticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.'''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Necessary until transformers packages is updated in the Kaggle notebook environment.\n!pip install --upgrade transformers\n\nimport transformers\nimport torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nmodel_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\",\n)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = '''Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. '''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are an assitant social studies teacher in a High School.\"},\n    {\"role\": \"user\", \"content\": prompt + passage},\n]\n\noutputs = pipeline(\n    messages,\n    max_new_tokens=2048,\n)\nprint(outputs[0][\"generated_text\"][-1])\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generated MCQS on ","metadata":{}},{"cell_type":"markdown","source":"\"**Section 1: Recall (Easy Difficulty Level)**\\n\\n1. What is Horticulture?\\n   a) Growing vegetables, flowers and fruits for commercial use\\n   b) Farming for subsistence\\n   c) Farming for commercial use\\n   d) Growing crops for household use\\n\\nAnswer: a) Growing vegetables, flowers and fruits for commercial use\\n\\n2. What are the important inputs in a farm system?\\n   a) Seeds, fertilisers, machinery and labour\\n   b) Seeds, fertilisers, animals and soil\\n   c) Seeds, labour, machinery and water\\n   d) Seeds, fertilisers, animals and tools\\n\\nAnswer: a) Seeds, fertilisers, machinery and labour\\n\\n3. What are the outputs from a farm system?\\n   a) Crops, wool, dairy and poultry products\\n   b) Crops, seeds, fertilisers and labour\\n   c) Crops, animals, tools and water\\n   d) Crops, animals, seeds and soil\\n\\nAnswer: a) Crops, wool, dairy and poultry products\\n\\n4. What is subsistence farming?\\n   a) Farming to meet the needs of the farmer's family\\n   b) Farming for commercial use\\n   c) Farming for household use\\n   d) Farming for export\\n\\nAnswer: a) Farming to meet the needs of the farmer's family\\n\\n5. What is intensive subsistence agriculture?\\n   a) Farming using simple tools and more labour\\n   b) Farming using complex tools and less labour\\n   c) Farming using animals and household labour\\n   d) Farming using machines and commercial labour\\n\\nAnswer: a) Farming using simple tools and more labour\\n\\n\n**Section 2: Analyze (Medium Difficulty Level)**\\n\\n6. What are the geographical conditions that permit intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Large number of days with sunshine and fertile soils\\n   b) Heavy rainfall and quick regeneration of vegetation\\n   c) Semi-arid and arid regions\\n   d) Thickly populated areas\\n\\nAnswer: a) Large number of days with sunshine and fertile soils\\n\\n7. What are the main crops grown in intensive subsistence agriculture? (Bloom's Taxonomy: Analyze)\\n   a) Rice, wheat, maize, pulses and oilseeds\\n   b) Maize, yam, potatoes and cassava\\n   c) Sheep, camel, yak and goats\\n   d) Cattle, buffalo and horses\\n\\nAnswer: a) Rice, wheat, maize, pulses and oilseeds\\n\\n8. What is shifting cultivation? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Shifting from one plot of land to another\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Shifting from one plot of land to another\\n\\n9. What is nomadic herding? (Bloom's Taxonomy: Analyze)\\n   a) Farming using simple tools and more labour\\n   b) Farming using animals and household labour\\n   c) Moving from place to place with animals for fodder and water\\n   d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n10. What are the products provided by sheep, camel, yak and goats in nomadic herding? (Bloom's Taxonomy: Analyze)\\n    a) Milk, meat, wool, hides and other products\\n    b) Crops, seeds, fertilisers and labour\\n    c) Crops, animals, tools and water\\n    d) Crops, animals, seeds and soil\\n\\nAnswer: a) Milk, meat, wool, hides and other products\\n\\n\n**Section 3: Evaluate (Hard Difficulty Level)**\\n\\n11. What are the limitations of subsistence farming? (Bloom's Taxonomy: Evaluate)\\n    a) Low levels of technology and household labour\\n    b) High levels of technology and commercial labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Low levels of technology and household labour\\n\\n12. What are the advantages of intensive subsistence agriculture? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: c) Large number of days with sunshine and fertile soils\\n\\n13. What are the limitations of shifting cultivation? (Bloom's Taxonomy: Evaluate)\\n    a) Soil loses its fertility and is abandoned\\n    b) Soil retains its fertility and is reused\\n    c) Large number of days with sunshine and fertile soils\\n    d) Heavy rainfall and quick regeneration of vegetation\\n\\nAnswer: a) Soil loses its fertility and is abandoned\\n\\n14. What are the advantages of nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) High levels of technology and commercial labour\\n    b) Low levels of technology and household labour\\n    c) Moving from place to place with animals for fodder and water\\n    d) Farming using machines and commercial labour\\n\\nAnswer: c) Moving from place to place with animals for fodder and water\\n\\n15. What are the geographical conditions that permit nomadic herding? (Bloom's Taxonomy: Evaluate)\\n    a) Large number of days with sunshine and fertile soils\\n    b) Heavy rainfall and quick regeneration of vegetation\\n    c) Semi-arid and arid regions\\n    d) Thickly populated areas\\n\\nAnswer: c) Semi-arid and arid regions\"}","metadata":{}},{"cell_type":"markdown","source":"# Fine-Tuning","metadata":{}},{"cell_type":"markdown","source":"## Using ADALORA\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 0.1 ******************************* \n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:54:51.471986Z","iopub.execute_input":"2024-10-04T05:54:51.473035Z","iopub.status.idle":"2024-10-04T05:55:11.042089Z","shell.execute_reply.started":"2024-10-04T05:54:51.472990Z","shell.execute_reply":"2024-10-04T05:55:11.040959Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.2 ******************************* \nimport bitsandbytes as bnb\nprint(bnb.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:55:11.044444Z","iopub.execute_input":"2024-10-04T05:55:11.044854Z","iopub.status.idle":"2024-10-04T05:55:14.263714Z","shell.execute_reply.started":"2024-10-04T05:55:11.044809Z","shell.execute_reply":"2024-10-04T05:55:14.262790Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"0.44.1\n","output_type":"stream"}]},{"cell_type":"code","source":"# ******************************* 0.3 ******************************* \n!pip install transformers\n!pip install peft  # This is for Parameter-Efficient Fine-Tuning (PEFT)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:55:14.264980Z","iopub.execute_input":"2024-10-04T05:55:14.265544Z","iopub.status.idle":"2024-10-04T05:55:41.910684Z","shell.execute_reply.started":"2024-10-04T05:55:14.265499Z","shell.execute_reply":"2024-10-04T05:55:41.909593Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting peft\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:55:41.913216Z","iopub.execute_input":"2024-10-04T05:55:41.913574Z","iopub.status.idle":"2024-10-04T05:55:41.918697Z","shell.execute_reply.started":"2024-10-04T05:55:41.913540Z","shell.execute_reply":"2024-10-04T05:55:41.917547Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# loading dataset","metadata":{}},{"cell_type":"code","source":"# ******************************* 1 ******************************* \nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/combined-data/combines_dataset.csv', encoding='ISO-8859-1')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:47.198634Z","iopub.execute_input":"2024-10-04T09:49:47.199518Z","iopub.status.idle":"2024-10-04T09:49:47.252384Z","shell.execute_reply.started":"2024-10-04T09:49:47.199476Z","shell.execute_reply":"2024-10-04T09:49:47.251318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.1 ******************************* \n# Display the first few rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:47.463325Z","iopub.execute_input":"2024-10-04T09:49:47.463685Z","iopub.status.idle":"2024-10-04T09:49:47.482233Z","shell.execute_reply.started":"2024-10-04T09:49:47.463630Z","shell.execute_reply":"2024-10-04T09:49:47.481400Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"                                             passage  \\\n0  This transformation from a plant to a finished...   \n1  People are a nationâs greatest resource. Nat...   \n2  Have you ever given a thought to the fact that...   \n3  In a small village in Tanzania, Africa, Mamba ...   \n4  Water, electricity, rickshaw, vegetable and te...   \n\n                                                mcqs  \n0  ['## Agriculture and Economic Activities: An M...  \n1  ['## Population Studies Test\\n', '\\n', '**Inst...  \n2  ['## The Journey of Your Notebook: A Social St...  \n3  ['## Social Studies Test: Land as a Resource\\n...  \n4  ['## Agriculture and Farming: An MCQ Test\\n', ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passage</th>\n      <th>mcqs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This transformation from a plant to a finished...</td>\n      <td>['## Agriculture and Economic Activities: An M...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>People are a nationâs greatest resource. Nat...</td>\n      <td>['## Population Studies Test\\n', '\\n', '**Inst...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Have you ever given a thought to the fact that...</td>\n      <td>['## The Journey of Your Notebook: A Social St...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In a small village in Tanzania, Africa, Mamba ...</td>\n      <td>['## Social Studies Test: Land as a Resource\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Water, electricity, rickshaw, vegetable and te...</td>\n      <td>['## Agriculture and Farming: An MCQ Test\\n', ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \n# Import the splitting function\nfrom sklearn.model_selection import train_test_split\n\n# Split the formatted data into training and testing sets\ntrain_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n\n# Check the lengths of the train and test splits\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Testing set size: {len(test_data)}\")\n\n# Optional: Print the first entry from the training and test set\nprint(f\"First training example: {train_data.iloc[0]}\")\nprint(len(train_data),\"\\n\")\nprint(f\"First testing example: {test_data.iloc[0]}\")\nprint(len(test_data))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:47.649297Z","iopub.execute_input":"2024-10-04T09:49:47.649610Z","iopub.status.idle":"2024-10-04T09:49:47.671549Z","shell.execute_reply.started":"2024-10-04T09:49:47.649577Z","shell.execute_reply":"2024-10-04T09:49:47.670663Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Training set size: 114\nTesting set size: 29\nFirst training example: passage    1. Peasants and Agricultural Production The ba...\nmcqs       ['## Peasant Life and Agriculture in Mughal In...\nName: 124, dtype: object\n114 \n\nFirst testing example: passage    1. A Mosaic of Religious Beliefs and Practices...\nmcqs       ['## MCQ Test: A Mosaic of Religious Beliefs\\n...\nName: 117, dtype: object\n29\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:48.853495Z","iopub.execute_input":"2024-10-04T09:49:48.854472Z","iopub.status.idle":"2024-10-04T09:49:48.859164Z","shell.execute_reply.started":"2024-10-04T09:49:48.854428Z","shell.execute_reply":"2024-10-04T09:49:48.858068Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"passages = train_data['passage'].tolist()\nmcqs = train_data['mcqs'].tolist()\n\npassage_test = test_data['passage'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:49.087221Z","iopub.execute_input":"2024-10-04T09:49:49.087570Z","iopub.status.idle":"2024-10-04T09:49:49.092471Z","shell.execute_reply.started":"2024-10-04T09:49:49.087535Z","shell.execute_reply":"2024-10-04T09:49:49.091546Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## New Prompt\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n\n<|start_header_id|>User<|end_header_id|>\npassage<|eot_id|>\n\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nmcqs<|eot_id|>\n\n<|end_of_text|>\n","metadata":{}},{"cell_type":"code","source":"# ******************************* 1.2 ******************************* \ntrain_data = []\n\nfor passage, mcq in zip(passages, mcqs):\n    formatted_entry = f'''\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n<|start_header_id|>User<|end_header_id|>\n{passage} <|eot_id|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\n{mcq}<|eot_id|>\n<|end_of_text|>\n'''\n    train_data.append(formatted_entry)\n\n# print(train_data[72])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:50.233151Z","iopub.execute_input":"2024-10-04T09:49:50.233824Z","iopub.status.idle":"2024-10-04T09:49:50.240899Z","shell.execute_reply.started":"2024-10-04T09:49:50.233784Z","shell.execute_reply":"2024-10-04T09:49:50.239718Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# ******************************* 1.3 ******************************* \nevaluation_data = []\n\nfor passage in (passage_test):\n    formatted_entry =  f'''\n<|begin_of_text|>\n<|start_header_id|>MCQs_Generator<|end_header_id|>\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. <|eot_id|>\n<|start_header_id|>User<|end_header_id|>\n{passage} <|eot_id|>\n<|end_of_text|>\n'''\n\n\n    evaluation_data.append(formatted_entry)\n\n# print(evaluation_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:50.943144Z","iopub.execute_input":"2024-10-04T09:49:50.943792Z","iopub.status.idle":"2024-10-04T09:49:50.949298Z","shell.execute_reply.started":"2024-10-04T09:49:50.943754Z","shell.execute_reply":"2024-10-04T09:49:50.948200Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, BitsAndBytesConfig\nfrom peft import get_peft_model, LoraConfig\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",  # You can choose \"fp4\" or \"nf4\"\n    bnb_4bit_use_double_quant=True,  # Optional: Use double quantization for better precision\n    bnb_4bit_compute_dtype=\"float16\"  # Set compute to float16 to save memory\n)\n\n# Load the model with the new quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,  # Use BitsAndBytesConfig for quantization\n    device_map='auto'  # Automatically map the model to available devices (e.g., GPU)\n)\n\n# Apply LoRA (Low-Rank Adaptation)\nlora_config = LoraConfig(\n    r=4,  # Low-rank dimension\n    lora_alpha=16,  # Scaling factor\n    lora_dropout=0.1,  # Dropout for LoRA layers\n    target_modules=[\"q_proj\", \"v_proj\"]  # Target layers for LoRA adaptation\n)\n\n# Wrap the model with QLoRA (Quantized Low-Rank Adaptation)\nmodel = get_peft_model(model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:56:24.768699Z","iopub.execute_input":"2024-10-04T05:56:24.769800Z","iopub.status.idle":"2024-10-04T05:57:43.920357Z","shell.execute_reply.started":"2024-10-04T05:56:24.769745Z","shell.execute_reply":"2024-10-04T05:57:43.919498Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9dbc1a9b28647609a5f0320a83a39fc"}},"metadata":{}}]},{"cell_type":"code","source":"# ******************************* 2.1 ******************************* \nfrom transformers import AutoTokenizer\n\ntokenizer_base = AutoTokenizer.from_pretrained(\"/kaggle/input/llama-3.1/transformers/8b-instruct/2/\")\ntokenizer_base.add_special_tokens({\n    'pad_token': '[PAD]',\n    'additional_special_tokens': ['<|begin_of_text|>', '<|start_header_id|>', '<|end_header_id|>', '<|eom_id|>', '<|eot_id|>', '<|end_of_text|>']\n})\n\n# Tokenize the formatted data\ntokenized_train_data = tokenizer_base(train_data, truncation=True, padding=\"max_length\", max_length=512)\ntokenized_eval_data = tokenizer_base(evaluation_data, truncation=True, padding=\"max_length\", max_length=512)\n\n# ******************************* 3 *******************************\n# Function to format tokenized data for the Trainer\ndef format_data_for_trainer(tokenized_data):\n    formatted_data = []\n    for i in range(len(tokenized_data['input_ids'])):\n        formatted_data.append({\n            'input_ids': tokenized_data['input_ids'][i],\n            'attention_mask': tokenized_data['attention_mask'][i],  # Include attention mask\n            'labels': tokenized_data['input_ids'][i]  # You can modify labels if needed\n        })\n    return formatted_data\n\nformatted_train_data = format_data_for_trainer(tokenized_train_data)\nformatted_eval_data = format_data_for_trainer(tokenized_eval_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:57:54.455400Z","iopub.execute_input":"2024-10-04T05:57:54.456336Z","iopub.status.idle":"2024-10-04T05:57:55.415068Z","shell.execute_reply.started":"2024-10-04T05:57:54.456293Z","shell.execute_reply":"2024-10-04T05:57:55.414229Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# print(len(tokenizer_base))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:52:48.877564Z","iopub.execute_input":"2024-10-04T03:52:48.878471Z","iopub.status.idle":"2024-10-04T03:52:48.907836Z","shell.execute_reply.started":"2024-10-04T03:52:48.878427Z","shell.execute_reply":"2024-10-04T03:52:48.906724Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"128257\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(tokenizer_base.vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:52:50.679547Z","iopub.execute_input":"2024-10-04T03:52:50.680222Z","iopub.status.idle":"2024-10-04T03:52:50.685211Z","shell.execute_reply.started":"2024-10-04T03:52:50.680182Z","shell.execute_reply":"2024-10-04T03:52:50.684217Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"128000\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T03:52:52.602147Z","iopub.execute_input":"2024-10-04T03:52:52.602934Z","iopub.status.idle":"2024-10-04T03:52:52.614909Z","shell.execute_reply.started":"2024-10-04T03:52:52.602892Z","shell.execute_reply":"2024-10-04T03:52:52.614032Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"PeftModel(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.resize_token_embeddings(len(tokenizer_base))","metadata":{"execution":{"iopub.status.busy":"2024-10-03T05:01:09.583872Z","iopub.execute_input":"2024-10-03T05:01:09.584248Z","iopub.status.idle":"2024-10-03T05:01:09.683704Z","shell.execute_reply.started":"2024-10-03T05:01:09.584211Z","shell.execute_reply":"2024-10-03T05:01:09.682748Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Embedding(128257, 4096)"},"metadata":{}}]},{"cell_type":"code","source":"# print(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T05:03:15.466515Z","iopub.execute_input":"2024-10-03T05:03:15.467447Z","iopub.status.idle":"2024-10-03T05:03:15.480377Z","shell.execute_reply.started":"2024-10-03T05:03:15.467405Z","shell.execute_reply":"2024-10-03T05:03:15.479220Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"PeftModel(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128257, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=4, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=4, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128257, bias=False)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# # ******************************* 3 ******************************* \n# from torch.utils.data import Dataset\n\n# class TextGenerationDataset(Dataset):\n#     def __init__(self, formatted_data, tokenizer, max_length=1024):\n#         self.formatted_data = formatted_data\n#         self.tokenizer = tokenizer\n#         self.max_length = max_length\n\n#     def __len__(self):\n#         return len(self.formatted_data)\n\n#     def __getitem__(self, idx):\n#         # Get the formatted entry\n#         formatted_entry = self.formatted_data[idx]\n        \n        \n#         # Tokenize the entire formatted entry\n#         encoding = self.tokenizer(\n#             formatted_entry,\n#             return_tensors='pt',\n#             max_length=self.max_length,\n#             padding='max_length',\n#             truncation=True\n#         )\n\n#         # Extract input_ids and create labels\n#         input_ids = encoding['input_ids'].squeeze()\n#         labels = input_ids.clone() \n\n#         return {'input_ids': input_ids, 'labels': labels}\n\n# # Prepare the dataset using the new formatted data\n# train_dataset = TextGenerationDataset(train_data, tokenizer_base)\n# test_dataset =  TextGenerationDataset(evaluation_data, tokenizer_base)\n\n# # Define the DataLoader if needed\n# # train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)  # Adjust batch size as needed","metadata":{"execution":{"iopub.status.busy":"2024-10-03T05:06:18.844117Z","iopub.execute_input":"2024-10-03T05:06:18.844815Z","iopub.status.idle":"2024-10-03T05:06:18.853226Z","shell.execute_reply.started":"2024-10-03T05:06:18.844773Z","shell.execute_reply":"2024-10-03T05:06:18.852220Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# ******************************* 3.1 ******************************* \nimport torch\nprint(torch.cuda.device_count())  \ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:58:00.736959Z","iopub.execute_input":"2024-10-04T05:58:00.737704Z","iopub.status.idle":"2024-10-04T05:58:00.743676Z","shell.execute_reply.started":"2024-10-04T05:58:00.737660Z","shell.execute_reply":"2024-10-04T05:58:00.742552Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Verify the type of datasets\n# print(type(train_dataset))\n# print(type(test_dataset))\nprint(type(formatted_train_data ))\nprint(type(formatted_eval_data))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:58:00.967102Z","iopub.execute_input":"2024-10-04T05:58:00.967779Z","iopub.status.idle":"2024-10-04T05:58:00.972940Z","shell.execute_reply.started":"2024-10-04T05:58:00.967735Z","shell.execute_reply":"2024-10-04T05:58:00.971920Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<class 'list'>\n<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(len(train_dataset))\n# print(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-10-03T14:59:38.405362Z","iopub.execute_input":"2024-10-03T14:59:38.406009Z","iopub.status.idle":"2024-10-03T14:59:38.820829Z","shell.execute_reply.started":"2024-10-03T14:59:38.405968Z","shell.execute_reply":"2024-10-03T14:59:38.819528Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_dataset))\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"],"ename":"NameError","evalue":"name 'train_dataset' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# from datasets import load_metric\n# bleu_metric = load_metric(\"bleu\")\n\n# def compute_metrics(eval_pred):\n#     predictions, labels = eval_pred\n#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n#     decoded_preds = [pred.split() for pred in decoded_preds]\n#     decoded_labels = [[label.split()] for label in decoded_labels]  # BLEU expects a list of references for each prediction\n    \n#     bleu_score = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n#     return {\"bleu\": bleu_score['bleu']}","metadata":{"execution":{"iopub.status.busy":"2024-10-03T05:06:22.615966Z","iopub.execute_input":"2024-10-03T05:06:22.616566Z","iopub.status.idle":"2024-10-03T05:06:22.621248Z","shell.execute_reply.started":"2024-10-03T05:06:22.616514Z","shell.execute_reply":"2024-10-03T05:06:22.620347Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# ******************************* 4 ******************************* \nfrom transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Define training arguments for multi-GPU and FP16\ntraining_args = TrainingArguments(\n    output_dir='./results_1',\n    num_train_epochs=40,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    save_steps=500,\n    save_total_limit=1,\n    logging_dir='./logs',\n    report_to='none',          # optional: to avoid logging issues with multiple GPUs\n    ddp_find_unused_parameters=True,  # required for multi-GPU\n    fp16=True,\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer_base, model=model)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=formatted_train_data,\n    eval_dataset=formatted_eval_data,\n#     data_collator=data_collator\n    )\n\n# Fine-tune the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:58:20.570835Z","iopub.execute_input":"2024-10-04T05:58:20.571710Z","iopub.status.idle":"2024-10-04T07:34:22.810305Z","shell.execute_reply.started":"2024-10-04T05:58:20.571668Z","shell.execute_reply":"2024-10-04T07:34:22.809182Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4560' max='4560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4560/4560 1:35:45, Epoch 40/40]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.705500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.426700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.222800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.013300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.831300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.675700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.557700</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.471700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.412400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4560, training_loss=0.9173854271570842, metrics={'train_runtime': 5747.5677, 'train_samples_per_second': 0.793, 'train_steps_per_second': 0.793, 'total_flos': 1.0515525566201856e+17, 'train_loss': 0.9173854271570842, 'epoch': 40.0})"},"metadata":{}}]},{"cell_type":"code","source":"print(trainer.model)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T05:51:57.103451Z","iopub.execute_input":"2024-10-04T05:51:57.103944Z","iopub.status.idle":"2024-10-04T05:51:57.430789Z","shell.execute_reply.started":"2024-10-04T05:51:57.103910Z","shell.execute_reply":"2024-10-04T05:51:57.429568Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel)\n","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"],"ename":"NameError","evalue":"name 'trainer' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Save the fine-tuned Model","metadata":{}},{"cell_type":"code","source":"# Save the model\ntrainer.save_model(\"./final_model\")  # Saves the model (LoRa weights will be part of it)\n\n# Save the tokenizer\ntokenizer_base.save_pretrained(\"./final_model\")\n\n# Save the LoRa adapter (LoRa-specific weights)\nmodel.save_pretrained(\"./final_model/lora\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T07:34:22.812063Z","iopub.execute_input":"2024-10-04T07:34:22.812839Z","iopub.status.idle":"2024-10-04T07:34:23.259933Z","shell.execute_reply.started":"2024-10-04T07:34:22.812798Z","shell.execute_reply":"2024-10-04T07:34:23.259074Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import shutil\n\n# Path to your model directory\nmodel_dir = '/kaggle/working/final_model'\n\n# Output zip file path\nzip_filename = '/kaggle/working/final_model.zip'\n\n# Zipping the directory\nshutil.make_archive(zip_filename.replace('.zip', ''), 'zip', model_dir)\n\nprint(\"Model zipped successfully!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T07:34:23.261252Z","iopub.execute_input":"2024-10-04T07:34:23.261603Z","iopub.status.idle":"2024-10-04T07:34:24.460244Z","shell.execute_reply.started":"2024-10-04T07:34:23.261568Z","shell.execute_reply":"2024-10-04T07:34:24.459264Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model zipped successfully!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing the model","metadata":{}},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-10-04T08:58:14.029400Z","iopub.execute_input":"2024-10-04T08:58:14.030352Z","iopub.status.idle":"2024-10-04T08:58:28.809929Z","shell.execute_reply.started":"2024-10-04T08:58:14.030298Z","shell.execute_reply":"2024-10-04T08:58:28.808835Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-10-04T08:58:28.812242Z","iopub.execute_input":"2024-10-04T08:58:28.812575Z","iopub.status.idle":"2024-10-04T08:58:41.880514Z","shell.execute_reply.started":"2024-10-04T08:58:28.812540Z","shell.execute_reply":"2024-10-04T08:58:41.879409Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.24.6)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-10-04T08:58:41.881860Z","iopub.execute_input":"2024-10-04T08:58:41.882179Z","iopub.status.idle":"2024-10-04T08:58:59.822779Z","shell.execute_reply.started":"2024-10-04T08:58:41.882145Z","shell.execute_reply":"2024-10-04T08:58:59.821790Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.44.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import LlamaForCausalLM, BitsAndBytesConfig, AutoTokenizer\nfrom peft import PeftModel\n\n# Define a BitsAndBytesConfig for 4-bit quantization\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_quant_type=\"nf4\",  # Choose \"nf4\" for better precision\n    bnb_4bit_use_double_quant=True,  # Optional: Use double quantization\n    bnb_4bit_compute_dtype=\"float16\"  # Set compute to float16 to save memory\n)\n\n# Load the fine-tuned model from Hugging Face\nfinetuned_model_path = \"/kaggle/input/llama3.1_15_epoch/transformers/v1/2\"  # Your fine-tuned model path on Hugging Face\n\n# Load the tokenizer used for fine-tuning\ntokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\nprint(\"0\")\n# Load the model with quantization config\nmodel = LlamaForCausalLM.from_pretrained(\n    finetuned_model_path,\n    ignore_mismatched_sizes=True,\n    quantization_config=quantization_config,  \n    device_map=\"auto\" \n)\nprint(\"1\")\n\n# Now load the LoRA adapter (if needed)\nlora_adapter_path = \"/kaggle/input/llama3.1_15_epoch/transformers/v1/2/lora\"\ntuned_model = PeftModel.from_pretrained(model, lora_adapter_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T08:58:59.824869Z","iopub.execute_input":"2024-10-04T08:58:59.825193Z","iopub.status.idle":"2024-10-04T09:00:43.879153Z","shell.execute_reply.started":"2024-10-04T08:58:59.825159Z","shell.execute_reply":"2024-10-04T09:00:43.878242Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01089dd8fcaf4257bfb5aa724715bf77"}},"metadata":{}},{"name":"stdout","text":"1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:00:46.665338Z","iopub.execute_input":"2024-10-04T09:00:46.665865Z","iopub.status.idle":"2024-10-04T09:00:46.670315Z","shell.execute_reply.started":"2024-10-04T09:00:46.665826Z","shell.execute_reply":"2024-10-04T09:00:46.669253Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"passage = '''Horticulture Growing vegetables, flowers and fruits for commercial use.\nFarm System Agriculture or farming can be looked at as a system. The important inputs are\nseeds, fertilisers, machinery and labour. Some of the operations involved are ploughing, sowing,\nirrigation, weeding and harvesting. The outputs from the system include crops, wool, dairy and\npoultry products. Types of Farming Farming is practised in various ways across the world.\nDepending upon the geographical conditions, demand of produce, labour and level of\ntechnology, farming can be classified into two main types. These are subsistence farming and\ncommercial farming. Subsistence Farming This type of farming is practised to meet the needs of\nthe farmer’s family. Traditionally, low levels of technology and household labour are used to\nproduce on small output. Subsistence farming can be further classified as intensive subsistence\nand primitive subsistence farming. In intensive subsistence agriculture the farmer cultivates a\nsmall plot of land using simple tools and more labour. Climate with large number of days with\nsunshine and fertile soils permit growing of more than one crop annually on the same plot. Rice\nis the main crop. Other crops include wheat, maize, pulses and oilseeds. Intensive subsistence\nagriculture is prevalent in the thickly populated areas of the monsoon regions of south,\nsoutheast and east Asia. Primitive subsistence agriculture includes shifting cultivation and\nnomadic herding. Shifting cultivation is practised in the thickly forested areas of Amazon basin,\ntropical Africa, parts of southeast Asia and Northeast India. These are the areas of heavy\nrainfall and quick regeneration of vegetation. A plot of land is cleared by felling the trees and\nburning them. The ashes are then mixed with the soil and crops like maize, yam, potatoes and\ncassava are grown. After the soil loses its fertility, the land is abandoned and the cultivator\nmoves to a new plot. Shifting cultivation is also known as ‘slash and burn’ agriculture. Nomadic\nherding is practised in the semi-arid and arid regions of Sahara, Central Asia and some parts of\nIndia, like Rajasthan and Jammu and Kashmir. In this type of farming, herdsmen move from\nplace to place with their animals for fodder and water, along defined routes. This type of\nmovement arises in response to climatic constraints and terrain. Sheep, camel, yak and goatsare most commonly reared. They provide milk, meat, wool, hides and other products to the\nherders and their families.'''","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:45:49.491779Z","iopub.execute_input":"2024-10-04T09:45:49.492171Z","iopub.status.idle":"2024-10-04T09:45:49.498846Z","shell.execute_reply.started":"2024-10-04T09:45:49.492133Z","shell.execute_reply":"2024-10-04T09:45:49.497809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"input_text = evaluation_data[9]\ninputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n\n# Generate text\nwith torch.no_grad():\n    outputs = tuned_model.generate(**inputs, max_length=4096)  \n\ngenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:00:49.991331Z","iopub.execute_input":"2024-10-04T09:00:49.992200Z","iopub.status.idle":"2024-10-04T09:01:01.285345Z","shell.execute_reply.started":"2024-10-04T09:00:49.992156Z","shell.execute_reply":"2024-10-04T09:01:01.283109Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtuned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      9\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:817\u001b[0m, in \u001b[0;36mPeftModel.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    816\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2017\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2018\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2019\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2021\u001b[0m     )\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   2037\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2038\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2039\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2979\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2985\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:387\u001b[0m, in \u001b[0;36mAlignDevicesHook.post_forward\u001b[0;34m(self, module, output)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_same_device \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:182\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n","File \u001b[0;32m<string>:8\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, loss, logits, past_key_values, hidden_states, attentions)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:376\u001b[0m, in \u001b[0;36mModelOutput.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m first_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, class_fields[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    374\u001b[0m other_fields_are_none \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, field\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m class_fields[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m--> 376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other_fields_are_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_field\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_field, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    378\u001b[0m         iterator \u001b[38;5;241m=\u001b[39m first_field\u001b[38;5;241m.\u001b[39mitems()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:127\u001b[0m, in \u001b[0;36mis_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    125\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(x)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_func \u001b[38;5;129;01min\u001b[39;00m framework_to_test_func\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Tracers\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:208\u001b[0m, in \u001b[0;36mis_tf_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tf_tensor\u001b[39m(x):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    Tests if `x` is a tensorflow tensor or not. Safe to call even if tensorflow is not installed.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_is_tensorflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:199\u001b[0m, in \u001b[0;36m_is_tensorflow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_tensorflow\u001b[39m(x):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mTensor)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/combinations.py:33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_lib\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_util\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mirrored_strategy\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_worker_util\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy_dataset\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_strategy.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values_util\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tfconfig_cluster_resolver\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_lib \u001b[38;5;28;01mas\u001b[39;00m input_lib_v1\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/cluster_resolver/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleClusterResolver\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnionClusterResolver\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgce_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCEClusterResolver\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkubernetes_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KubernetesClusterResolver\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslurm_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SlurmClusterResolver\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/cluster_resolver/gce_cluster_resolver.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m _GOOGLE_API_CLIENT_INSTALLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m discovery  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleCredentials  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/discovery.py:64\u001b[0m\n\u001b[1;32m     61\u001b[0m     HAS_UNIVERSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Local imports\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _auth, mimeparse\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_query_parameter, positional\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogleapiclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m     HttpError,\n\u001b[1;32m     68\u001b[0m     InvalidJsonError,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     UnknownFileType,\n\u001b[1;32m     73\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/googleapiclient/_auth.py:34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     HAS_OAUTH2CLIENT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/oauth2client/client.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m HAS_CRYPTO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m crypt\n\u001b[1;32m     46\u001b[0m     HAS_CRYPTO \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     HAS_OPENSSL \u001b[38;5;241m=\u001b[39m crypt\u001b[38;5;241m.\u001b[39mOpenSSLVerifier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/oauth2client/crypt.py:55\u001b[0m\n\u001b[1;32m     52\u001b[0m     pkcs12_key_as_pem \u001b[38;5;241m=\u001b[39m _bad_pkcs12_key_as_pem\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moauth2client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pycrypto_crypt\n\u001b[1;32m     56\u001b[0m     PyCryptoSigner \u001b[38;5;241m=\u001b[39m _pycrypto_crypt\u001b[38;5;241m.\u001b[39mPyCryptoSigner\n\u001b[1;32m     57\u001b[0m     PyCryptoVerifier \u001b[38;5;241m=\u001b[39m _pycrypto_crypt\u001b[38;5;241m.\u001b[39mPyCryptoVerifier\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/oauth2client/_pycrypto_crypt.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"pyCrypto Crypto-related routines for oauth2client.\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SHA256\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPublicKey\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RSA\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSignature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PKCS1_v1_5\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUtil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masn1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DerSequence\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/Crypto/PublicKey/RSA.py:43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUtil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masn1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DerSequence, DerNull\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mUtil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bytes_to_long\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMath\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mNumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integer\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMath\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPrimality\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (test_probable_prime,\n\u001b[1;32m     45\u001b[0m                                    generate_probable_prime, COMPOSITE)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPublicKey\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_expand_subject_public_key_info,\n\u001b[1;32m     48\u001b[0m                               _create_subject_public_key_info,\n\u001b[1;32m     49\u001b[0m                               _extract_subject_public_key_info)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/Crypto/Math/Numbers.py:34\u001b[0m\n\u001b[1;32m     31\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteger\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMath\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_IntegerGMP\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntegerGMP \u001b[38;5;28;01mas\u001b[39;00m Integer\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCrypto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMath\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_IntegerGMP\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m implementation \u001b[38;5;28;01mas\u001b[39;00m _implementation\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/Crypto/Math/_IntegerGMP.py:100\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot using GMP on Windows\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mload_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmp_defs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m implementation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgmp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi\u001b[39m\u001b[38;5;124m\"\u001b[39m: backend}\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(lib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mpir_version\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/Crypto/Util/_raw_api.py:103\u001b[0m, in \u001b[0;36mload_lib\u001b[0;34m(name, cdecl)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a shared library and return a handle to it.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m@name,  either an absolute path or the name of a library\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m@cdecl, the C function declarations.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ffi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRTLD_DEEPBIND\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYCRYPTODOME_DISABLE_DEEPBIND\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 103\u001b[0m     lib \u001b[38;5;241m=\u001b[39m \u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRTLD_DEEPBIND\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     lib \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39mdlopen(name)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cffi/api.py:150\u001b[0m, in \u001b[0;36mFFI.dlopen\u001b[0;34m(self, name, flags)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlopen(name): name must be a file name, None, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor an already-opened \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoid *\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 150\u001b[0m     lib, function_cache \u001b[38;5;241m=\u001b[39m \u001b[43m_make_ffi_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_caches\u001b[38;5;241m.\u001b[39mappend(function_cache)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libraries\u001b[38;5;241m.\u001b[39mappend(lib)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cffi/api.py:832\u001b[0m, in \u001b[0;36m_make_ffi_library\u001b[0;34m(ffi, libname, flags)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[1;32m    831\u001b[0m     backend \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m--> 832\u001b[0m     backendlib \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccessor_function\u001b[39m(name):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/cffi/api.py:818\u001b[0m, in \u001b[0;36m_load_backend_lib\u001b[0;34m(backend, name, flags)\u001b[0m\n\u001b[1;32m    816\u001b[0m         first_error \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m,):\n","File \u001b[0;32m/opt/conda/lib/python3.10/ctypes/util.py:350\u001b[0m, in \u001b[0;36mfind_library\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _findLib_prefix(so_name) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    345\u001b[0m            _findLib_prefix(name) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    346\u001b[0m            _findSoname_ldconfig(name) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    347\u001b[0m            _get_soname(_findLib_gcc(name)) \u001b[38;5;129;01mor\u001b[39;00m _get_soname(_findLib_ld(name))\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m _findLib_prefix(name) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m--> 350\u001b[0m             \u001b[43m_findSoname_ldconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    351\u001b[0m             _get_soname(_findLib_gcc(name)) \u001b[38;5;129;01mor\u001b[39;00m _get_soname(_findLib_ld(name))\n","File \u001b[0;32m/opt/conda/lib/python3.10/ctypes/util.py:290\u001b[0m, in \u001b[0;36m_findSoname_ldconfig\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    288\u001b[0m regex \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfsencode(regex \u001b[38;5;241m%\u001b[39m (re\u001b[38;5;241m.\u001b[39mescape(name), abi_type))\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/sbin/ldconfig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                          \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLC_ALL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLANG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    295\u001b[0m         res \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(regex, p\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m res:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1809\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_child_created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;66;03m# be sure the FD is closed no matter what\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrpipe_write\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[1;32m   1812\u001b[0m                      c2pread, c2pwrite,\n\u001b[1;32m   1813\u001b[0m                      errread, errwrite)\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;66;03m# Wait for exec to fail or succeed; possibly raising an\u001b[39;00m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;66;03m# exception (limited in size)\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"print(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T05:52:18.544517Z","iopub.execute_input":"2024-10-03T05:52:18.545400Z","iopub.status.idle":"2024-10-03T05:52:18.549905Z","shell.execute_reply.started":"2024-10-03T05:52:18.545359Z","shell.execute_reply":"2024-10-03T05:52:18.549038Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"\n\nMCQs_Generator\nYou are a helpful MCQ Generator and Today you have to conduct a MCQ based test on a given topic. For the test generate 15 MCQs from the following passage with the answer key.\nThe Test consists of three different sections where each section contains 5 questions each of easy, medium and hard difficulty level.\nUse Bloom's Taxonomy to define the difficulty level of the question.\nRemember the questions should be from the passage only. \nUser\n1. A Mosaic of Religious Beliefs and Practices\nPerhaps the most striking feature of this phase is the increasing visibility of a wide range of gods\nand goddesses in sculpture as well as in texts. At one level, this indicates the continued and\neven extended worship of the major deities â Vishnu, Shiva and the goddess â each of whom\nwas visualised in a variety of forms.\n1.1 The integration of cults\nHistorians who have tried to understand these developments suggest that there were at least\ntwo processes at work. One was a process of disseminating Brahmanical ideas. This is\nexemplified by the composition, compilation and preservation of Puranic texts in simple Sanskrit\nverse, explicitly meant to be accessible to women and Shudras, who were generally excluded\nfrom Vedic learning. At the same time, there was a second process at work â that of the\nBrahmanas accepting and reworking the beliefs and practices of these and other social\ncategories. In fact, many beliefs and practices were shaped through a continuous dialogue\nbetween what sociologists have described as âgreatâ Sanskritic Puranic traditions and âlittleâ\ntraditions throughout the land. One of the most striking examples of this process is evident at\nPuri, Orissa, where the principal deity was identified, by the twelfth century, as Jagannatha\n(literally, the lord of the world), a form of Vishnu. If you compare Fig. 6.2 with Fig. 4.26 (Chapter\n4) you will notice that the deity is represented in a very different way. In this instance, a local\ndeity, whose image was and continues to be made of wood by local tribal specialists, was\nrecognised as a form of Vishnu. At the same time, Vishnu was visualised in a way that was very\ndifferent from that in other parts of the country. Such instances of integration are evident\namongst goddess cults as well. Worship of the goddess, often simply in the form of a stone\nsmeared with ochre, was evidently widespread. These local deities were often incorporated\nwithin the Puranic framework by providing them with an identity as a wife of the principal male\ndeities â sometimes they were equated with Lakshmi, the wife of Vishnu, in other instances, with\nParvati, the wife of Shiva.\n1.2 Difference and conflict\nOften associated with the goddess were forms of worship that were classified as Tantric. Tantric\npractices were widespread in several parts of the subcontinent â they were open to women and\nmen, and practitioners often ignored differences of caste and class within the ritual context.\nMany of these ideas influenced Shaivism as well as Buddhism, especially in the eastern,\nnorthern and southern parts of the subcontinent. All of these somewhat divergent and even\ndisparate beliefs and practices would come to be classified as Hindu over the course of the next\nmillennium. The divergence is perhaps most stark if we compare Vedic and Puranic traditions.\nThe principal deities of the Vedic pantheon, Agni, Indra and Soma, become marginal figures,\nrarely visible in textual or visual representations. And while we can catch a glimpse of Vishnu,\nShiva and the goddess in Vedic mantras, these have little in common with the elaborate Puranic\nmythologies. However, in spite of these obvious discrepancies, the Vedas continued to be\nrevered as authoritative. Not surprisingly, there were sometimes conflicts as well â those who\nvalued the Vedic tradition often condemned practices that went beyond the closely regulated\ncontact with the divine through the performance of sacrifices or precisely chanted mantras. On\nthe other hand those engaged in Tantric practices frequently ignored the authority of the Vedas.\nAlso, devotees often tended to project their chosen deity, either Vishnu or Shiva, as supreme.\nRelations with other traditions, such as Buddhism or Jainism, were also often fraught withtension if not open conflict. The traditions of devotion or bhakti need to be located within this\ncontext. Devotional worship had a long history of almost a thousand years before the period we\nare considering. During this time, expressions of devotion ranged from the routine worship of\ndeities within temples to ecstatic adoration where devotees attained a trance-like state. The\nsinging and chanting of devotional compositions was often a part of such modes of worship.\nThis was particularly true of the Vaishnava and Shaiva sects.\n2. Poems of Prayer Early Traditions of Bhakti\nIn the course of the evolution of these forms of worship, in many instances, poet-saints emerged\nas leaders around whom there developed a community of devotees. Further, while Brahmanas\nremained important intermediaries between gods and devotees in several forms of bhakti, these\ntraditions also accommodated and acknowledged women and the âlower castesâ, categories\nconsidered ineligible for liberation within the orthodox Brahmanical framework. What also\ncharacterised traditions of bhakti was a remarkable diversity. At a different level, historians of\nreligion often classify bhakti traditions into two broad categories: saguna (with attributes) and\nnirguna (without attributes). The former included traditions that focused on the worship of\nspecific deities such as Shiva, Vishnu and his avatars (incarnations) and forms of the goddess\nor Devi, all often conceptualised in anthropomorphic forms. Nirguna bhakti on the other hand\nwas worship of an abstract form of god.\n2.1 The Alvars and Nayanars of Tamil Nadu\nSome of the earliest bhakti movements (c. sixth century) were led by the Alvars (literally, those\nwho are âimmersedâ in devotion to Vishnu) and Nayanars (literally, leaders who were devotees\nof Shiva). They travelled from place to place singing hymns in Tamil in praise of their gods.\nDuring their travels the Alvars and Nayanars identified certain shrines as abodes of their chosen\ndeities. Very often large temples were later built at these sacred places. These developed as\ncentres of pilgrimage. Singing compositions of these poet-saints became part of temple rituals in\nthese shrines, as did worship of the saintsâ images.\n2.2 Attitudes towards caste\nSome historians suggest that the Alvars and Nayanars initiated a movement of protest against\nthe caste system and the dominance of Brahmanas or at least attempted to reform the system.\nTo some extent this is corroborated by the fact that bhaktas hailed from diverse social\nbackgrounds ranging from Brahmanas to artisans and cultivators and even from castes\nconsidered âuntouchableâ. The importance of the traditions of the Alvars and Nayanars was\nsometimes indicated by the claim that their compositions were as important as the Vedas. For\ninstance, one of the major anthologies of compositions by the Alvars, the Nalayira\nDivyaprabandham, was frequently described as the Tamil Veda, thus claiming that the text was\nas significant as the four Vedas in Sanskrit that were cherished by the Brahmanas.\n2.3 Women devotees\nPerhaps one of the most striking features of these traditions was the presence of women. For\ninstance, the compositions of Andal, a woman Alvar, were widely sung (and continue to be sung\nto date). Andal saw herself as the beloved of Vishnu; her verses express her love for the deity.\nAnother woman, Karaikkal Ammaiyar, a devotee of Shiva, adopted the path of extreme\nasceticism in order to attain her goal. Her compositions were preserved within the Nayanar\ntradition. These women renounced their social obligations, but did not join an alternative orderor become nuns. Their very existence and their compositions posed a chall \n\n easy\nThe Test\n1. Easy\n1.1\nWhat is the significance of the fact that the Alvars and Nayanars travelled from place to place\nsinging hymns in Tamil in praise of their gods?\n(i) They were trying to spread the message of devotion.\n(ii) They wanted to reach out to people who did not have access to the Vedic tradition.\n(iii) They were trying to create a sense of unity among the people.\n(iv) They were trying to create a sense of identity with their chosen deity.\n1.2\nHow did the Alvars and Nayanars view the importance of the Vedas?\n(i) They considered the Alvars and Nayanars as equal to the Vedic rishis.\n(ii) They believed that the Tamil compositions of the Alvars and Nayanars were as important\nas the four Vedas.\n(iii) They believed that the Alvars and Nayanars were more devoted to their gods than the\nBrahmanas were to the Vedic tradition.\n(iv) They believed that the Alvars and Nayanars were more devoted to their gods than the\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2024-10-04T07:53:39.612365Z","iopub.execute_input":"2024-10-04T07:53:39.612778Z","iopub.status.idle":"2024-10-04T07:53:39.617437Z","shell.execute_reply.started":"2024-10-04T07:53:39.612740Z","shell.execute_reply":"2024-10-04T07:53:39.616293Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"prompt = '''From now on you are an assistant teacher in a high school. Today you have to conduct an MCQ-based test. \nFor the test generate 15 MCQs from the following passage with the answer key at the last. \nThe Test consists of three different sections and each section contains 5 questions each of easy, medium and hard difficulty levels. \nUse Bloom's Taxonomy to define the difficulty level of the question. \nEasy Questions require a simple recall of facts or basic concepts.\nMedium Questions require understanding, application, or analysis of information.\nHard Questions require synthesis or evaluation of information.\nEnsure that two consecutive questions should not have the same option as the answer.\nIf so, reorder the questions. Also, ensure that options 'B' and 'C' are more likely to be the correct answers in all the sections.\nPlease remember that the questions should be from the passage only.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:45:51.268496Z","iopub.execute_input":"2024-10-04T09:45:51.269217Z","iopub.status.idle":"2024-10-04T09:45:51.273895Z","shell.execute_reply.started":"2024-10-04T09:45:51.269177Z","shell.execute_reply":"2024-10-04T09:45:51.272943Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# input_text = evaluation_data[0]\ninput_text = prompt + passage\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n\n# Get the length of the input (this helps in slicing the generated text)\ninput_length = inputs['input_ids'].shape[1]\n\n# Generate text\nwith torch.no_grad():\n    outputs = tuned_model.generate(\n        **inputs,\n        max_length=2048,  # Adjust max_length as needed\n        pad_token_id=tokenizer.eos_token_id,  # Ensure it pads correctly\n        eos_token_id=tokenizer.eos_token_id,\n        num_return_sequences=1\n    )\n\n# Decode the output, but only from the input length onwards\ngenerated_text = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:46:02.894030Z","iopub.execute_input":"2024-10-04T09:46:02.894916Z","iopub.status.idle":"2024-10-04T09:48:21.614338Z","shell.execute_reply.started":"2024-10-04T09:46:02.894874Z","shell.execute_reply":"2024-10-04T09:48:21.613044Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":" Commercial Farming Commercial farming is practised for earning\nincome from the farm. The farmer is motivated to increase the output of the farm and to\nminimise the costs of production. The main goal of commercial farming is to maximise profits.\nCommercial farming is practised in developed and developing countries. In developed\ncountries, commercial farming is practised on large areas of land. The farmers use high levels\nof technology and high levels of labour are not used. The production is directed towards meeting\nthe demands of the urban population. Commercial farming in developed countries is\npractised on a large scale and is highly mechanised. The farmers use high levels of technology\nand high levels of labour are not used. The production is directed towards meeting the demands\nof the urban population. In developing countries, commercial farming is practised on small\nareas of land. The farmers use low levels of technology and high levels of labour are used.\nCommercial Farming in India In India, commercial farming is practised on the large farms of\nlandlords and also on the small farms of the small farmers. The farmers use low levels of\ntechnology and high levels of labour are used. Commercial farming is mainly concentrated in\nthe fertile alluvial plains of the Ganga and Brahmaputra rivers. The main crops grown in this\nregion are wheat, rice, maize and sugarcane. The areas around the Himalayas, the Vindhyas\nand the Western Ghats are also suitable for commercial farming. These regions have fertile soil\nand adequate rainfall. The main crops grown in these regions are wheat, rice, maize, sugarcane, pulses, oilseeds and spices. The plateau region is suitable for commercial farming of\ncotton, jute, tobacco, tea, coffee, rubber and oil palm. The Deccan plateau is also suitable for\ncommercial farming of sugarcane, cotton, tobacco and oilseeds. In the arid and semi-arid\nregions of Rajasthan, Gujarat, Madhya Pradesh and parts of Andhra Pradesh and Karnataka,\ncommercial farming of wheat, rice, maize, sugarcane, cotton, tobacco and oilseeds is practised.\nIn the Himalayan region, commercial farming of tea, coffee, rubber, cardamom, cinchona and\npotatoes is practised. In the hill regions of Andhra Pradesh and Karnataka, commercial farming\nof coffee, tea and rubber is practised. In the northeastern region, commercial farming of tea,\ncoffee, rubber, cardamom and cinchona is practiced. In the Andaman and Nicobar Islands,\ncommercial farming of coconut, rubber, areca nut, betel leaves, cardamom, cinnamon and\nchillies is practised. Horticulture Horticulture is the cultivation of flowers, fruits and vegetables\nfor commercial use. The main products of horticulture are flowers, fruits, vegetables, tea,\ncoffee, rubber, cardamom, cinchona, potatoes, spices, nuts, seeds, feed crops and ornamental\nplants. Horticulture is practiced in India in the plains and in the hill regions. The main areas of\nhorticulture in India are the plains, the hill regions of the Himalayas, the Western Ghats, the\nEastern Ghats and the Andaman and Nicobar Islands. The main products of horticulture are\nflowers, fruits, vegetables, tea, coffee, rubber, cardamom, cinchona, potatoes, spices, nuts,\nseeds, feed crops and ornamental plants. The major horticultural crops grown in India are\npotatoes, sugarcane, citrus, mango, banana, coconut, chilies, cardamom, coffee, tea, rubber,\ntobacco and flowers. Horticulture is practiced in India in the plains and in the hill regions. The\nmain areas of horticulture in India are the plains, the hill regions of the Himalayas, the Western\nGhats, the Eastern Ghats and the Andaman and Nicobar Islands. The main products of\nhorticulture are flowers, fruits, vegetables, tea, coffee, rubber, cardamom, cinchona, potatoes,\nspices, nuts, seeds, feed crops and ornamental plants. The major horticultural crops grown\nin India are potatoes, sugarcane, citrus, mango, banana, coconut, chilies, cardamom, coffee,\ntea, rubber, tobacco and flowers. Horticultural Crops Horticultural crops are grown on\nsmall areas of land. The production of horticultural crops is seasonal and is affected by\nweather conditions. The main factors that affect the production of horticultural crops are\ntemperature, rainfall, soil, sunlight and pests. Horticultural Crops Horticultural crops are grown\non small areas of land. The production of horticultural crops is seasonal and is affected by\nweather conditions. The main factors that affect the production of horticultural crops are\ntemperature, rainfall, soil, sunlight and pests. Horticultural crops can be classified into three\ntypes. These are vegetables, fruits and flowers. Vegetables are grown for their edible parts.\nThe edible parts can be roots, tubers, stems, leaves and flowers. The common vegetables\ngrown in India are potatoes, tomatoes, cauliflower, cabbage, brinjal, chillies, onions and\ngarlic. Fruits are grown for their edible parts, which are the fleshy parts of the plants. The common\nfruits grown in India are mango, banana, citrus, coconut, grapes, apples, pears, peaches,\napricots and plums. Flowers are grown for their aesthetic value. The common flowers grown\nin India are roses, carnations, chrysanthemums, marigolds, zinnias, sunflowers, gladiolus and\ndahlias. Horticultural Crops Horticultural crops are grown on small areas of land. The\nproduction of horticultural crops is seasonal and is affected by weather conditions. The main\nfactors that affect the production of horticultural crops are temperature, rainfall, soil, sunlight\nand pests. Horticultural crops can be classified into three types. These are vegetables, fruits\nand flowers. Vegetables are grown for their edible parts. The edible parts can be roots, tubers,\nstems, leaves and flowers. The common vegetables grown in India are potatoes, tomatoes,\ncauliflower, cabbage, brinjal, chillies, onions\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Validation on SuperGlue Score","metadata":{}},{"cell_type":"code","source":"\nprint(torch.cuda.device_count())  # Check number of GPUs available\nprint(torch.cuda.get_device_name(1))  # Check the name of the second GPU\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:48:38.016759Z","iopub.execute_input":"2024-10-04T09:48:38.017123Z","iopub.status.idle":"2024-10-04T09:48:38.023270Z","shell.execute_reply.started":"2024-10-04T09:48:38.017091Z","shell.execute_reply":"2024-10-04T09:48:38.022273Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"2\nTesla T4\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:48:39.355316Z","iopub.execute_input":"2024-10-04T09:48:39.356054Z","iopub.status.idle":"2024-10-04T09:48:52.115199Z","shell.execute_reply.started":"2024-10-04T09:48:39.356015Z","shell.execute_reply":"2024-10-04T09:48:52.113974Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('super_glue', 'boolq') ","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:48:52.117577Z","iopub.execute_input":"2024-10-04T09:48:52.118483Z","iopub.status.idle":"2024-10-04T09:49:05.409525Z","shell.execute_reply.started":"2024-10-04T09:48:52.118420Z","shell.execute_reply":"2024-10-04T09:49:05.408837Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/30.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f909da96314046b287857b7f43c09bf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/18.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb8fcd244d5408d8b09d0c053f05645"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for super_glue contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/super_glue.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78d7b9915d214e069e6bdd8e74db0df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7bd190112544563be356a6425faa982"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3270 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9d56cd69ea24ef59abd7fda1524d54d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13142183703b40d7bd9c18df494ccd38"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_metric\n\n# Load the BoolQ dataset and metric\nboolq_dataset = load_dataset('super_glue', 'boolq', split='validation')\naccuracy_metric = load_metric('accuracy')\n\n# device = torch.device(\"cuda:0\")\n# model = model.to(device)\n# Evaluate the model\npredictions = []\nfor example in boolq_dataset:\n    input_text = tokenizer(evaluation_data, return_tensors=\"pt\", padding=True, truncation=True)\n    input_ids = input_text[\"input_ids\"]\n    attention_mask = input_text[\"attention_mask\"]\n\n    # Run the model with the extracted input_ids and attention_mask\n    predicted_label = tuned_model(input_ids=input_ids, attention_mask=attention_mask)\n    predictions.append(predicted_label)\n\n# Calculate accuracy\naccuracy = accuracy_metric.compute(predictions=predictions, references=boolq_dataset['label'])\nprint(f\"BoolQ accuracy: {accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T09:49:57.751560Z","iopub.execute_input":"2024-10-04T09:49:57.751931Z","iopub.status.idle":"2024-10-04T09:50:00.272843Z","shell.execute_reply.started":"2024-10-04T09:49:57.751896Z","shell.execute_reply":"2024-10-04T09:50:00.271406Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [66,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [35,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m input_text[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Run the model with the extracted input_ids and attention_mask\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mtuned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(predicted_label)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:812\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    811\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:965\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     past_seen_tokens \u001b[38;5;241m=\u001b[39m past_key_values\u001b[38;5;241m.\u001b[39mget_seq_length() \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 965\u001b[0m     cache_position \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"markdown","source":"# ________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________","metadata":{}},{"cell_type":"code","source":"passage = '''This chapter deals with one of the most difficult challenges faced by independent India—poverty. After discussing this multi-dimensional problem through examples, the chapter discusses the way poverty is seen in social sciences. Poverty trends in India and the world are illustrated through the concept of the poverty line. Causes of poverty as well as anti-poverty measures taken by the government are also discussed. The chapter ends with broadening the official concept of poverty into human poverty. In our daily life, we come across many people who we think are poor. They could be landless labourers in villages or people living in overcrowded jhuggis in cities. They could be daily wage workers at construction sites or child workers in dhabas. They could also be beggars with children in tatters. We see poverty all around us. In fact, every fifth person in India is poor. (This means, roughly 270 million (or 27 crore) people in India live in poverty 2011-12.) This also means that India has the largest single concentration of the poor in the world. This illustrates the seriousness of the challenge. Urban Case Thirty-three year old Ram Saran works as a daily-wage labourer in a wheat flour mill near Ranchi in Jharkhand. He manages to earn around Rs 1,500 a month when he finds employment, which is not often. The money is not enough to sustain his family of six— that includes his wife and four children aged between 12 years to six months. He has to send money home to his old parents who live in a village near Ramgarh. His father a landless labourer, depends on Ram Saran and his brother who lives in Hazaribagh, for sustenance. Ram Saran lives in a one-room rented house in a crowded basti in the outskirts of the city. It’s a\ntemporary shack built of bricks and clay tiles. His wife Santa Devi, works as a part time maid in a few houses and manages to earn another Rs 800. They manage a meagre meal of dal and\nrice twice a day, but there’s never enough for all of them. His elder son works as a helper in a tea shop to supplement the family income and earns another Rs 300, while his 10- year-old daughter takes care of the younger siblings. None of the children go to school. They have only two pairs of hand-me-down clothes each. New ones are bought only when the old clothes become unwearable. Shoes are a luxury. The younger kids are undernourished. They have no access to healthcare when they fall ill. Rural case Lakha Singh belongs to a small village near Meerut in Uttar Pradesh. His family doesn’t own any land, so they do odd jobs for the big farmers. Work is erratic and so is income. At times they get paid Rs 50 for a hard day’s work. But often it’s in kind like a few kilograms of wheat or dal or even vegetables for toiling in the farm through the day. The family of eight cannot always manage two square meals a day. Lakha lives in a kuchha hut on the outskirts of the village. The women of the family spend the day chopping fodder and collecting firewood in the fields. His father a TB patient, passed away two years ago due to lack of medication. His mother now suffers from the same disease and life is slowly ebbing away.Although, the village has a primary school, Lakha never went there. He had to start earning when he was 10 years old. New clothes happen once in a few years. Even soap and oil are a luxury for the family. These two typical cases illustrate many dimensions of poverty. They show that poverty means hunger and lack of shelter. It also is a situation in which parents are\nnot able to send their children to school or a situation where sick people cannot afford treatment. Poverty also means lack of clean water and sanitation facilities. It also means lack of a regular job at a minimum decent level. Above all it means living with a sense of helplessness. Poor people are in a situation in which they are ill-treated at almost every place, in farms, factories, government offices, hospitals, railway stations etc. Obviously, nobody would like to live in poverty. One of the biggest challenges of independent India has been to bring millions of its people out of abject poverty. Mahatama Gandhi always insisted that India would be truly independent only when the poorest of its people become free of human suffering. Poverty as seen by social scientists Since poverty has many facets, social scientists look at it through a variety of indicators. Usually the indicators used relate to the levels of income and consumption. But now poverty is looked through other social indicators like illiteracy level, lack of general resistance due to malnutrition, lack of access to healthcare, lack of job opportunities, lack\nof access to safe drinking water, sanitation etc. Analysis of poverty based on social exclusion and vulnerability is now becoming very common.Social exclusion According to this concept, poverty must be seen in terms of the poor having to live only in a poor surrounding with other poor people, excluded from enjoying social equality of better-off people in better surroundings. Social exclusion can be both a cause as well as a consequence of poverty in the usual sense. Broadly, it is a process through which individuals or groups are excluded from facilities, benefits and opportunities that others (their “betters”) enjoy. A typical example is the working of the caste system in India in which people belonging to certain castes are excluded from equal opportunities. Social exclusion thus may lead to, but can cause more damage than, having a very low income. Vulnerability to poverty is a measure, which describes the greater\nprobability of certain communities (say, members of a backward caste) or individuals (such as a widow or a physically handicapped person) of becoming, or remaining, poor in the coming years. Vulnerability is determined by the options available to different communities for finding\nan alternative living in terms of assets, education, health and job opportunities. Further, it is analysed on the basis of the greater risks these groups face at the time of natural disasters (earthquakes, tsunami), terrorism etc. Additional analysis is made of their social and economic\nability to handle these risks. In fact, vulnerability describes the greater probability of being more adversely affected than other people when bad time comes for everybody, whether a\nflood or an earthquake or simply a fall in the availability of jobs!\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}